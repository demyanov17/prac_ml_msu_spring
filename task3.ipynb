{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dmk-ZbAOt4xr"
   },
   "source": [
    "# Третье практическое задание. Реализация дропаута в рекуррентных нейронных сетях\n",
    "Практикум на ЭВМ для 317 группы, весна 2022\n",
    "\n",
    "#### Фамилия, имя: Демьянов Иван\n",
    "\n",
    "Дата выдачи: 3 апреля 18:00\n",
    "\n",
    "Мягкий дедлайн: 17 апреля 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSrO8O4ct4xu"
   },
   "source": [
    "Данное задание будет состоять из двух частей:\n",
    "1. Применение рекуррентной сети для решения задачи классификации текста. Более конкретно -- предсказания рейтинга отзыва фильма.\n",
    "2. Простейшая лингвистическая модель для генерации текста на основе LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6Eyr79qt4xv"
   },
   "source": [
    "При выполнении задания вы обучите LSTM с разным уровнем \"коробочности\", а также познакомитесь с различными способами применения DropOut к рекуррентным архитектурам. В рекуррентных архитектурах вариантов, куда можно наложить бинарную маску шума, гораздо больше, чем в нейросетях прямого прохода.\n",
    "\n",
    "Во второй части вы попробуете реализовать простейший рекуррентный декодер для генерации текстов.\n",
    "\n",
    "Задание сделано так, чтобы его можно было выполнять на CPU, однако RNN - это ресурсоёмкая вещь, поэтому на GPU с ними работать приятнее. Можете попробовать использовать [https://colab.research.google.com](https://colab.research.google.com) - бесплатное облако с GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDtUlpsct4xw"
   },
   "source": [
    "**Для корректного отображения картинок, вам может понадобится сделать ноутбук доверенным (Trusted) в правом верхнем углу**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R9sixljt4xx"
   },
   "source": [
    "# Часть 0. Загрузка и предобработка данных. (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkAK5wgBt4xx"
   },
   "source": [
    "## Рекомендуемые гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:04:28.454122Z",
     "start_time": "2021-04-02T00:04:28.438278Z"
    },
    "id": "HGL8Je16t4xy"
   },
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "top_n_words = 5000\n",
    "\n",
    "hidden_dim = 128\n",
    "embedding_dim = 32\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F7LOwLwt4xz"
   },
   "source": [
    "Первое, что нужно сделать -- скачать, предобработать данные и организовать их таким образом, чтобы их можно было подавать в нейронную сеть.\n",
    "\n",
    "Для обеих частей задания мы будем использовать [**Large Movie Review Dataset**](https://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THbZqyf2t4x0"
   },
   "source": [
    "## Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCpOTED2t4x1"
   },
   "source": [
    "Загрузите данные по ссылке выше. (**tip**: используйте `wget`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:34:47.261797Z",
     "start_time": "2021-03-30T18:34:33.768597Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7U8IMect4x1",
    "outputId": "80433dbc-331b-4bab-8eef-9e4ee5e8041b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-17 17:28:22--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar’\n",
      "\n",
      "aclImdb_v1.tar      100%[===================>]  80.23M  28.9MB/s    in 2.8s    \n",
      "\n",
      "2022-04-17 17:28:25 (28.9 MB/s) - ‘aclImdb_v1.tar’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "!wget 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36sDTAzrt4x4"
   },
   "source": [
    "Распакуйте скачанные данные в папку `aclImdb` (**tip:** используйте `tar`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T17:48:59.763990Z",
     "start_time": "2021-03-30T17:48:56.998383Z"
    },
    "id": "aRkQjQgCt4x5"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import tarfile\n",
    "\n",
    "aclImdb = tarfile.open(name='aclImdb_v1.tar', mode='r')\n",
    "aclImdb.extractall()\n",
    "aclImdb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_k0eAyyt4x6"
   },
   "source": [
    "Посмотрите в файле `./aclImdb/README` как организованы данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T23:55:43.946032Z",
     "start_time": "2021-04-01T23:55:43.814779Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZNkYEcCt4x6",
    "outputId": "ca281a82-8b00-4e9b-9282-0263433a19be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well."
     ]
    }
   ],
   "source": [
    "! cat ./aclImdb/train/pos/10003_8.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:04:33.729663Z",
     "start_time": "2021-04-02T00:04:33.710871Z"
    },
    "id": "4qqkeFDpt4x9"
   },
   "outputs": [],
   "source": [
    "test_data_path = './aclImdb/test/'\n",
    "train_data_path = './aclImdb/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnhXzqbBu90z",
    "outputId": "a65a6e60-f30e-40aa-f4e0-8a1d3dad6711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.12.0 in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (1.11.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (4.64.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (1.21.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext==0.12.0) (4.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchtext==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpkwQhzkt4x-",
    "outputId": "b5f974e2-cf8b-44b7-b4c5-6d7fe3046230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:04:33.709378Z",
     "start_time": "2021-04-02T00:04:32.220580Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmhqQNu3t4x_",
    "outputId": "a050e427-5b81-4017-f3a9-570fab901415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import regex\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ivtmP3ft4yA"
   },
   "source": [
    "Стандартной предобработкой данных является токенизация текстов. Полученные токены можно будет закодировать и затем подавать на вход нейронной сети. Ключевым моментом, который влияет на скорость работы нейросети и её размер в памяти -- размер словаря, используемого при токенизации. Для задачи классификации мы можем убрать часть слов (стоп слова, редкие слова), ускорив обучение без потери в качестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:04:35.270825Z",
     "start_time": "2021-04-02T00:04:35.250283Z"
    },
    "id": "tPqd0N8ht4yB"
   },
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBzGcVBt4yC"
   },
   "source": [
    "Реализуйте функцию для токенизации текста. Выполнять токенизацию можно по-разному, но в данном задании предлагается это делать следующим образом:\n",
    "1. Привести текст к нижнему регистру\n",
    "2. Убрать html разметку из текстов (`<br />`)\n",
    "3. Убрать все символы кроме латинских букв\n",
    "4. Разбить строку по пробелам\n",
    "5. Убрать стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:04:36.003194Z",
     "start_time": "2021-04-02T00:04:35.980408Z"
    },
    "id": "49WIB5H8t4yD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param str text: Input text \n",
    "    :return List[str]: List of words\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    text = text.lower()\n",
    "    text = re.sub('<br />', '', text)\n",
    "    text = re.sub('[^a-z ]', '', text).split(' ')\n",
    "    return [t for t in text if t not in STOPWORDS and t!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRAGyLs9t4yE",
    "outputId": "22794993-b33c-466c-9ad9-96efeca6cd63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'words']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('1. Hello <br /> words!! <br />')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFHXJIgwt4yF"
   },
   "source": [
    "Теперь мы можем создать словарь, с помощью которого мы будем численно кодировать токены из текста и наоборот.\n",
    "\n",
    "Удобной обёрткой для создания словарей является класс `torchtext.vocab.Vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:27:21.466887Z",
     "start_time": "2021-04-01T21:27:21.352085Z"
    },
    "id": "ParFSzTGt4yF"
   },
   "outputs": [],
   "source": [
    "torchtext.vocab.Vocab??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T19:51:55.300753Z",
     "start_time": "2021-04-01T19:51:55.275188Z"
    },
    "id": "Ki42W8Zst4yG"
   },
   "source": [
    "Чтобы создать такой словарь, сначала нужно создать словарь со всеми токенами в тексте и их частотами встречаемости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:13.547038Z",
     "start_time": "2021-04-02T00:04:38.190688Z"
    },
    "id": "RbmCD-I2t4yG"
   },
   "outputs": [],
   "source": [
    "counter = defaultdict(int)\n",
    "\n",
    "for path in ['./aclImdb/test/neg', './aclImdb/test/pos', './aclImdb/train/neg', './aclImdb/train/pos']:\n",
    "    for file_path in os.listdir(path):\n",
    "        text = open(os.path.join(path, file_path), 'r', encoding='utf-8', errors='ignore').read().strip()\n",
    "        for token in tokenize(text):\n",
    "            counter[token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI3jTjqSt4yH"
   },
   "source": [
    "Для работы с текстами нам необходимо зарезервировать два специальных токена:\n",
    "1. `<pad>` для токена означающего паддинг\n",
    "2. `<unk>` для токенов, которые отсутствуют в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:28:18.239274Z",
     "start_time": "2021-04-01T21:28:18.214979Z"
    },
    "id": "D2H8SfDft4yH"
   },
   "outputs": [],
   "source": [
    "specials = ['<pad>', '<unk>']\n",
    "for special in specials:\n",
    "    counter[special] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UDNI_0pt4yI"
   },
   "source": [
    "Создайте словарь из словаря частот `counter`. Наименьшие id отдайте под специальные токены. Отбросьте низкочастотные слова, оставив только `top_n_words` слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0IG9VpH4t4yO"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "for i, l in counter.items():\n",
    "    c[i] = l\n",
    "\n",
    "new_counter = {}\n",
    "for i, l in c.most_common(top_n_words):\n",
    "    new_counter[i] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RsCeTj6qt4yR"
   },
   "outputs": [],
   "source": [
    "vocab = torchtext.vocab.vocab(new_counter, specials=specials, special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB_S7dePt4yS",
    "outputId": "7bc3b7e8-5591-405d-fe27-05979cb2ab1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(['<pad>', '<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_Oz1wMjt4yS",
    "outputId": "80460a32-3088-4bed-85ce-439d6da889a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 1, 272]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(['this', 'film', 'was', 'awful'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUaX0nDNt4yV"
   },
   "source": [
    "Теперь мы готовы создать обёртку-датасет для наших данных. \n",
    "\n",
    "Необходимо добавить несколько опции, которые понадобятся во второй части задания:\n",
    "1. Ограничение на максимальную длину текста в токенах. Если текст оказывается длиннее, то последние токены отбрасываются\n",
    "2. Возможность добавить в специальные токены `<sos>`, `<eos>` в начало и конец токенизированного текста\n",
    "    \n",
    "**tips:**\n",
    "1. Обратите особое внимание, что у длинных текстов не должен обрезаться паддинг\n",
    "2. В исходных данных рейтинг закодирован в названии файла в виде числа от 1 до 10. Для удобства, вычтите 1, чтобы рейтинг был от 0 до 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:13.573249Z",
     "start_time": "2021-04-02T00:05:13.548593Z"
    },
    "id": "fUCCvQSat4yW"
   },
   "outputs": [],
   "source": [
    "class LargeMovieReviewDataset(Dataset):\n",
    "    def __init__(self, data_path, vocab, max_len, pad_sos=False, pad_eos=False):\n",
    "        \"\"\"\n",
    "        :param str data_path: Path to folder with one of the data splits (train or test)\n",
    "        :param torchtext.vocab.Vocab vocab: dictionary with lookup_indices method\n",
    "        :param int max_len: Maximum length of tokenized text\n",
    "        :param bool pad_sos: If True pad sequence at the beginning with <sos> \n",
    "        :param bool pad_eos: If True pad sequence at the end with <eos>         \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pad_sos = pad_sos\n",
    "        if self.pad_sos:\n",
    "            self.sos_id = vocab.lookup_indices(['<sos>'])[0]\n",
    "        self.pad_eos = pad_eos\n",
    "        if self.pad_eos:\n",
    "            self.eos_id = vocab.lookup_indices(['<eos>'])[0]\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        self.data_path = data_path\n",
    "        self.negative_path = os.path.join(data_path, 'neg')\n",
    "        self.positive_path = os.path.join(data_path, 'pos')\n",
    "        \n",
    "        self.negative_paths = []\n",
    "        self.positive_paths = []\n",
    "\n",
    "        for file_path in os.listdir(self.negative_path):\n",
    "            self.negative_paths.append(os.path.join(self.negative_path, file_path))\n",
    "\n",
    "        for file_path in os.listdir(self.positive_path):\n",
    "            self.positive_paths.append(os.path.join(self.positive_path, file_path))\n",
    "        \n",
    "        self.texts = []\n",
    "        self.tokens = []\n",
    "        self.ratings = []\n",
    "        self.labels = [0] * len(self.negative_paths) + [1] * len(self.positive_paths)\n",
    "        \n",
    "        # Read each file in data_path, tokenize it, get tokens ids, its rating and store\n",
    "        for path in self.negative_paths + self.positive_paths:\n",
    "            # YOUR CODE HERE\n",
    "            with open(path) as f:\n",
    "                text = f.read()\n",
    "                self.texts.append(text)\n",
    "                text_tokens = []\n",
    "                if self.pad_sos:\n",
    "                    text_tokens.append(self.sos_id)\n",
    "                for token in tokenize(text)[:self.max_len]:\n",
    "                    text_tokens.append(vocab.lookup_indices([token])[0])\n",
    "                if self.pad_eos:\n",
    "                    text_tokens.append(self.eos_id)\n",
    "                self.tokens.append(torch.tensor(text_tokens, dtype=torch.long))\n",
    "                self.ratings.append(int(path.split('_')[-1].split('.')[0]) - 1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        :param int idx: index of object in dataset\n",
    "        :return dict: Dictionary with all useful object data \n",
    "            {\n",
    "                'text' str: unprocessed text,\n",
    "                'label' torch.tensor(dtype=torch.long): sentiment of the text (0 for negative, 1 for positive)\n",
    "                'rating' torch.tensor(dtype=torch.long): rating of the text\n",
    "                'tokens' torch.tensor(dtype=torch.long): tensor of tokens ids for the text\n",
    "                'tokens_len' torch.tensor(dtype=torch.long): number of tokens\n",
    "            }\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Do not forget to add padding if needed!\n",
    "        return {\n",
    "            'text': self.texts[idx],\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            'rating': torch.tensor(self.ratings[idx], dtype=torch.long),\n",
    "            'tokens': self.tokens[idx],\n",
    "            'tokens_len': torch.tensor(self.tokens[idx].size(0), dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return int: number of objects in dataset \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cljQrHSst4yX"
   },
   "source": [
    "Создайте датасеты для тестовой и обучающей выборки. \n",
    "\n",
    "Обратите внимание, что для задачи классификации нам не потребуется паддинг с помощью `<sos>`, `<eos>`. \n",
    "\n",
    "Не забудьте обрезать длинные тексты, передав параметр `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:31:32.123618Z",
     "start_time": "2021-04-01T21:30:54.950259Z"
    },
    "id": "H2HLKpM-t4yX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "test_dataset = LargeMovieReviewDataset(test_data_path, vocab, max_length)\n",
    "train_dataset = LargeMovieReviewDataset(train_data_path, vocab, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CixGMfmet4yY"
   },
   "source": [
    "Посмотрим, как выглядит объект в датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:31:36.017106Z",
     "start_time": "2021-04-01T21:31:35.988797Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2faXPO4t4yY",
    "outputId": "f2ecb3dd-effb-40cd-a40a-855efb6d100d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'rating': tensor(2),\n",
       " 'text': 'You know, I\\'m getting really tired of all the generic music being used in these type of movies (see Jawbreaker, Disturbing Behavior, etc). Every scene of genuine tension here (and there is some) is immediately undercut with some cheesy pop tune, completely diluting the suspense. Why do they do that? To sell some soundtracks, of course, but in this case, mission unaccomplished - did anyone buy the CD?<br /><br />And yeah, Ms. Mirren attacks her role with zest and relish (with some cheez-wiz to add kick). But what are Molly, Leslie and Vivica doing here? Their roles (they\\'re so underused that I cannot use \"characters\" here) have no purpose in the storyline, so I can\\'t figure out why three well-known actresses had been cast.<br /><br />Oh, and the ending is so unbelievably hackneyed and irresponsible. The kids get off scot-free and act as if nothing happened - all smiles at graduation. They\\'re criminals, people! No consequences for their actions (kidnapping, assault, grade tampering) - nothing.<br /><br />Little things too - was Tingle\\'s tale about her husband true? What\\'s with the crossbow? Would the virginal Katie character loose her cherry on a whim like that? (Great message, guys.) Why did McKean go to her home? How did Kate\\'s academic nemesis walk through the door at that exact moment? How do students even obtain teachers\\' home addresses? WHAT\\'S WITH JEFFREY TAMBOR?? On what basis did McKean fire Tingle? She\\'s bloodied, battered and held hostage by students, fer cripe\\'s sake!<br /><br />Oh well, I\\'m spending way more thought on the script than Mr. Williamson apparently did, so I\\'ll stop here.<br /><br />3/10',\n",
       " 'tokens': tensor([  41,   55,  261,   10, 1238, 3610,  109,  216,  450,   22,   11,    1,\n",
       "         1082, 1729,  437,   75,   48, 1713,  960, 1047,    1,  771, 1523, 2873,\n",
       "          215,    1,  665, 1916,    1,  157,  304, 1705,    1,  147,  649,    1,\n",
       "         1038, 1406,    1, 2699,  118,    1,    1,    1,  595, 1929, 4926, 2979,\n",
       "            1,  466,  371,    1,  434,  235,   28, 1108,  627,   79,  704,  180,\n",
       "         4352, 1464,    1,  170, 3625,    1,    1,  224,   15,    1,  382,   69,\n",
       "          468,    1,    1,  371, 2729,   19, 3020, 1476,    1, 4370, 1472,    1,\n",
       "            1,   84,    1,  663,  550,  184,  581,    1,    8,    1,    1,   34,\n",
       "         1617,    1,    1,    5,   16,  615,  299,    1,   53,  237,    1,    1,\n",
       "            1, 1040, 1175, 2315,  442, 1239,    7,    1, 4477,  237,    1,  581,\n",
       "         4202,    1, 2723,    1,  858,    1,  330,    1,    1, 1491,    1, 1239,\n",
       "            1,    1,    1,   14,   55, 3013,   27,   97,  131,  337,    1,  552,\n",
       "          430,  470]),\n",
       " 'tokens_len': tensor(146)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkBrPdPBt4yY"
   },
   "source": [
    "Теперь нам нужно создать `DataLoader` для наших данных. `DataLoader` умеет из коробки объединять список объектов из датасета в один батч, даже когда датасет возвращает словарь тензоров. Однако, это работает только в случае когда все эти тензоры имеют один и тот же размер во всех батчах. В нашем случае, это не так, так как разные тексты могут иметь разную длину.\n",
    "\n",
    "Чтобы обойти эту проблему у `DataLoader` есть параметр `collate_fn`, который позволяет задать функцию для объединения списка объектов в один батч."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY8hcveyt4yZ"
   },
   "source": [
    "Чтобы объединить несколько тензоров разной длины в один можно использовать функцию `torch.nn.utils.rnn.pad_sequence`\n",
    "\n",
    "Обратите внимание на её аргументы:\n",
    "1. `batch_first` определяет по какой оси \"складывать\" тензоры. Предпочтительнее использовать `batch_first=False` так как это может упростить выполнение задания в дальнейшем \n",
    "2. `padding_value` -- число, которое будет использоваться в качестве паддинга, чтобы сделать все тензоры одинаковой длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:33:06.372403Z",
     "start_time": "2021-04-01T21:33:06.344559Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRUCQc1It4yZ",
    "outputId": "d7b18aae-4651-4ba7-fbe8-4de175acfa40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  6],\n",
       "        [ 2,  5,  7],\n",
       "        [ 3, -1,  8],\n",
       "        [-1, -1,  9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_sequence([\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([4, 5]),\n",
    "    torch.tensor([6, 7, 8, 9])\n",
    "], batch_first=False, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5ZPH3W_kMdCV"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, padding_value, batch_first=False):\n",
    "    \"\"\"\n",
    "    :param List[Dict] batch: List of objects from dataset\n",
    "    :param int padding_value: Value that will be used to pad tokens\n",
    "    :param bool batch_first: If True resulting tensor with tokens must have shape [B, T] otherwise [T, B]\n",
    "    :return dict: Dictionary with all data collated\n",
    "        {\n",
    "            'ratings' torch.tensor(dtype=torch.long): rating of the text for each object in batch\n",
    "            'labels' torch.tensor(dtype=torch.long): sentiment of the text for each object in batch\n",
    "            \n",
    "            'texts' List[str]: All texts in one list\n",
    "            'tokens' torch.tensor(dtype=torch.long): tensor of tokens ids padded with @padding_value\n",
    "            'tokens_lens' torch.tensor(dtype=torch.long): number of tokens for each object in batch\n",
    "        }\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    d = batch[0].copy()\n",
    "    replacements = {'text': 'texts', 'label': 'labels', 'rating': 'ratings',\n",
    "                    'tokens_len': 'tokens_lens'}\n",
    "    for i in list(d.keys()):\n",
    "        if i in replacements.keys():\n",
    "            d[replacements[i]] = d.pop(i)\n",
    "    tokens = [d['tokens']]\n",
    "    for obj in batch[1:]:\n",
    "        d['texts'] += obj['text']\n",
    "\n",
    "        d['ratings'] = torch.cat((d['ratings'].reshape(-1), obj['rating'].reshape(-1)))\n",
    "        d['labels'] = torch.cat((d['labels'].reshape(-1), obj['label'].reshape(-1)))\n",
    "        d['tokens_lens'] = torch.cat((d['tokens_lens'].reshape(-1), obj['tokens_len'].reshape(-1)))\n",
    "        tokens.append(obj['tokens'])\n",
    "    \n",
    "    d['tokens'] = torch.nn.utils.rnn.pad_sequence(tokens, batch_first=batch_first,\n",
    "                                                        padding_value=padding_value)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhpEYrEBt4ya"
   },
   "source": [
    "Создайте даталоадеры с использованием `collate_fn`.\n",
    "\n",
    "**tips**:\n",
    "1. Передать в `collate_fn` правильное значение паддинга можно, например, с помощью `functools.partial`\n",
    "2. Если вы работаете в Google Colab, то, возможно, вам будет необходимо установить `num_workers=0` во избежание падения ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:33:37.872760Z",
     "start_time": "2021-04-01T21:33:37.847071Z"
    },
    "id": "XhdGfCjPt4yb"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from functools import partial\n",
    "\n",
    "new_collate = partial(collate_fn, padding_value=0, batch_first=False)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                             collate_fn=new_collate, shuffle=True, num_workers=0)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              collate_fn=new_collate, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-xMPaLIt4yc"
   },
   "source": [
    "Посмотрим на какой-нибудь батч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:33:46.922744Z",
     "start_time": "2021-04-01T21:33:46.755275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WckQW3lAt4yd",
    "outputId": "e6eae529-a251-4a19-f848-89b0d2593bdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['tokens', 'texts', 'labels', 'ratings', 'tokens_lens']),\n",
       " tensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1]),\n",
       " tensor([2, 8, 1, 9, 2, 2, 0, 3, 9, 0, 0, 8, 9, 0, 0, 3, 3, 8, 0, 9, 2, 3, 8, 7,\n",
       "         8, 3, 6, 8, 8, 2, 2, 0, 0, 8, 7, 9, 6, 7, 0, 6, 7, 0, 9, 9, 9, 9, 0, 9,\n",
       "         7, 0, 2, 0, 0, 2, 0, 0, 8, 7, 0, 1, 0, 9, 0, 9]),\n",
       " tensor([[  55,    2,   58,  ...,   21,    2,    1],\n",
       "         [  95,   16,    6,  ..., 1481,   29, 1345],\n",
       "         [ 213,  902,    2,  ...,   19,  891, 4458],\n",
       "         ...,\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
       " tensor([175,  46,  46,  63,  56, 101, 117,  64, 200,  66,  96,  50,  99, 118,\n",
       "          80,  65, 186,  29,  99,  22,  36, 200,  54,  63,  77, 161, 157, 200,\n",
       "         140, 175, 200, 200,  73,  68, 131, 130, 156,  72,  31,  73,  51,  74,\n",
       "          49,  64,  98,  52,  54,  40, 165,  64, 142, 200, 200, 116, 147,  77,\n",
       "          65,  73, 117,  55, 120,  74,  50,  73]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "batch.keys(), batch['labels'], batch['ratings'], batch['tokens'], batch['tokens_lens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be1ZKl5Ft4ye"
   },
   "source": [
    "# Часть 1. Классификация текстов. (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kqa2wL1t4ye"
   },
   "source": [
    "## Сборка и обучение RNN в pytorch (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDeCQbw4t4ye"
   },
   "source": [
    "Создадим переменные для device-agnostic кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:13.809416Z",
     "start_time": "2021-04-02T00:05:13.711383Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6tjpgEjt4yf",
    "outputId": "8f77a7fb-2678-4e3c-e34b-fa077d2522ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0, dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "dtype, device, cuda_device_id = torch.float32, None, 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
    "if cuda_device_id is not None and torch.cuda.is_available():\n",
    "    device = 'cuda:{0:d}'.format(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using device: {device}, dtype: {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnU2QoLyt4yf"
   },
   "source": [
    "Наша нейросеть будет обрабатывать входную последовательность по словам (word level). Мы будем использовать простую и стандартную рекуррентную архитектуру для классификации:\n",
    "1. Слой представлений, превращающий id токена в вектор-ембеддинг этого слова\n",
    "2. Слой LSTM\n",
    "3. Полносвязный слой, предсказывающий выход по последнему скрытому состоянию\n",
    "\n",
    "Ниже дан код для сборки и обучения нашей нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJQfod3Yt4yg"
   },
   "source": [
    "Допишите класс-обёртку над LSTM для задачи классификации. \n",
    "**Не используйте циклы.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T20:59:16.467178Z",
     "start_time": "2021-04-01T20:59:16.441112Z"
    },
    "id": "1o5e7eGHt4yg"
   },
   "source": [
    "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:13.873713Z",
     "start_time": "2021-04-02T00:05:13.810690Z"
    },
    "id": "hMnLvlwet4yg"
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, embedding_dim, hidden_dim, output_size, vocab,\n",
    "        rec_layer=torch.nn.LSTM, dropout=None, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Create a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "        #    Use torch.nn.Embedding. Do not forget specify padding_idx!\n",
    "        # YOUR CODE HERE\n",
    "        self.word_embeddings = torch.nn.Embedding(len(self.vocab), self.embedding_dim, padding_idx=0)\n",
    "        \n",
    "        if dropout is not None:\n",
    "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, dropout=self.dropout, **kwargs)\n",
    "        else:\n",
    "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, **kwargs)\n",
    "         \n",
    "        # Create linear layer for classification\n",
    "        # YOUR CODE HERE\n",
    "        self.output = torch.nn.Linear(self.hidden_dim, self.output_size, bias=False)\n",
    "    \n",
    "    def forward(self, tokens, tokens_lens):\n",
    "        \"\"\"\n",
    "        :param torch.tensor(dtype=torch.long) tokens: Batch of texts represented with tokens.\n",
    "        :param torch.tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch.\n",
    "        :return torch.tensor(dtype=torch.long): Vector representation for each sequence in batch\n",
    "        \"\"\"\n",
    "        # Evaluate embeddings\n",
    "        # YOUR CODE HERE\n",
    "        layer1 = self.word_embeddings(tokens) # layer1[max_length, batch_size, embedding_dim]\n",
    "        \n",
    "        # Make forward pass through recurrent network\n",
    "        # YOUR CODE HERE\n",
    "        out, hidden = self.rnn(layer1) # out:[max_length, batch_size, self.hidden_dim]\n",
    "        # hidden: ([1, batch_size, self.hidden_dim], [1, batch_size, self.hidden_dim])\n",
    "        \n",
    "        # Pass output from rnn to linear layer \n",
    "        # Note: each object in batch has its own length \n",
    "        #     so we must take rnn hidden state after the last token for each text in batch\n",
    "        # YOUR CODE HERE\n",
    "        return self.output(out[tokens_lens-1, torch.arange(out.size(1)), :]) #[batch_size, output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ441N3ct4yh"
   },
   "source": [
    "[Исходный код LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIguYlggt4yh"
   },
   "source": [
    "Допишите функции для обучения и оценки модели:\n",
    "\n",
    "**tip:**\n",
    "1. В функции `evaluate` при подсчёте метрик учитывайте, что батчи могут иметь разный размер. (в частности последний батч)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:13.969665Z",
     "start_time": "2021-04-02T00:05:13.875379Z"
    },
    "id": "g3uyBwi1t4yi"
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    #model = model.to(device)\n",
    "    model.train()\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        # 1. Take data from batch\n",
    "        # 2. Perform forward pass\n",
    "        # 3. Evaluate loss\n",
    "        # 4. Make optimizer step\n",
    "        # YOUR CODE HERE\n",
    "        optimizer.zero_grad()\n",
    "        tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
    "        labels = data['ratings'].to(device)\n",
    "        predict = model(tokens, tokens_lens)\n",
    "        loss = loss_fn(predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    \n",
    "def evaluate(dataloader, model, loss_fn, device):\n",
    "    #model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            # 1. Take data from batch\n",
    "            # 2. Perform forward pass\n",
    "            # 3. Evaluate loss\n",
    "            # 4. Evaluate accuracy\n",
    "            # YOUR CODE HERE\n",
    "            tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
    "            labels = data['ratings'].to(device)\n",
    "            predict = model(tokens, tokens_lens)\n",
    "            total_loss += loss_fn(predict, labels)\n",
    "            total_accuracy += torch.sum((torch.argmax(predict, dim=1) == labels))\n",
    "    return total_loss / len(dataloader.dataset), total_accuracy / len(dataloader.dataset)\n",
    "\n",
    "def train(\n",
    "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
    "):\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
    "        \n",
    "        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(\n",
    "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
    "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
    "            )\n",
    "        )\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTNDMC1Qt4yi"
   },
   "source": [
    "Создадим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:39:36.315652Z",
     "start_time": "2021-04-01T21:39:33.667776Z"
    },
    "id": "xqyJoJZ_t4yj"
   },
   "outputs": [],
   "source": [
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
    "    rec_layer=torch.nn.LSTM, dropout=None\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKHKof7Xt4yj"
   },
   "source": [
    "Создадим класс для подсчёта функции потерь и оптимизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:39:38.737281Z",
     "start_time": "2021-04-01T21:39:38.711948Z"
    },
    "id": "fsC33USSt4yk"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf-RmABwt4yk"
   },
   "source": [
    "Попробуем обучить модель:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6ut6bBNt4yl"
   },
   "source": [
    "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:44:27.733745Z",
     "start_time": "2021-04-01T21:41:52.821042Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRORNbnKt4yl",
    "outputId": "9dd988b3-e8c4-4b8b-8163-df8ce6f58b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 1.892/1.901. Accuracy (Train/Test): 0.301/0.306\n",
      "Epoch: 2/15. Loss (Train/Test): 1.743/1.767. Accuracy (Train/Test): 0.341/0.341\n",
      "Epoch: 3/15. Loss (Train/Test): 1.623/1.678. Accuracy (Train/Test): 0.369/0.357\n",
      "Epoch: 4/15. Loss (Train/Test): 1.545/1.627. Accuracy (Train/Test): 0.393/0.374\n",
      "Epoch: 5/15. Loss (Train/Test): 1.464/1.586. Accuracy (Train/Test): 0.431/0.383\n",
      "Epoch: 6/15. Loss (Train/Test): 1.437/1.584. Accuracy (Train/Test): 0.441/0.384\n",
      "Epoch: 7/15. Loss (Train/Test): 1.354/1.565. Accuracy (Train/Test): 0.468/0.399\n",
      "Epoch: 8/15. Loss (Train/Test): 1.322/1.576. Accuracy (Train/Test): 0.486/0.396\n",
      "Epoch: 9/15. Loss (Train/Test): 1.258/1.579. Accuracy (Train/Test): 0.511/0.394\n",
      "Epoch: 10/15. Loss (Train/Test): 1.198/1.617. Accuracy (Train/Test): 0.537/0.385\n",
      "Epoch: 11/15. Loss (Train/Test): 1.132/1.644. Accuracy (Train/Test): 0.568/0.386\n",
      "Epoch: 12/15. Loss (Train/Test): 1.057/1.687. Accuracy (Train/Test): 0.604/0.378\n",
      "Epoch: 13/15. Loss (Train/Test): 0.987/1.781. Accuracy (Train/Test): 0.633/0.369\n",
      "Epoch: 14/15. Loss (Train/Test): 0.909/1.811. Accuracy (Train/Test): 0.666/0.374\n",
      "Epoch: 15/15. Loss (Train/Test): 0.821/1.908. Accuracy (Train/Test): 0.713/0.359\n",
      "working time is 2m 14s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVIiou-pt4yl"
   },
   "source": [
    "Нерегуляризованные LSTM часто быстро переобучаются (и мы это видим по точности на контроле). Чтобы с этим бороться, часто используют L2-регуляризацию и дропаут.\n",
    "Однако способов накладывать дропаут на рекуррентный слой достаточно много, и далеко не все хорошо работают. По [ссылке](https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) доступен хороший обзор дропаутов для RNN.\n",
    "\n",
    "Мы реализуем два варианта DropOut для RNN (и третий дополнительно). Заодно увидим, что для реализации различных усовершенствований рекуррентной архитектуры приходится \"вскрывать\" слой до различной \"глубины\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyh-xAc-t4yl"
   },
   "source": [
    "## Реализация дропаута по статье Гала и Гарамани. Variational Dropout. (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE0GyZrtt4ym"
   },
   "source": [
    "Начнем с дропаута, описанного в [статье Гала и Гарамани](https://arxiv.org/abs/1512.05287).\n",
    "Для этого нам потребуется перейти от использования слоя `torch.nn.LSTM`, полностью скрывающего от нас рекуррентную логику, к использованию слоя `torch.nn.LSTMCell`, обрабатывающего лишь один временной шаг нашей последовательности (а всю логику вокруг придется реализовать самостоятельно). \n",
    "\n",
    "Допишите класс `RNNLayer`. При `dropout=0` ваш класс должен работать как обычный слой LSTM, а при `dropout > 0` накладывать бинарную маску на входной и скрытый вектор на каждом временном шаге, причем эта маска должна быть одинаковой во все моменты времени.\n",
    "\n",
    "Дропаут Гала и Гарамани в виде формул (m обозначает маску дропаута):\n",
    "\n",
    "$$\n",
    "h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n",
    "$$\n",
    "\n",
    "Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n",
    "\n",
    "$$\n",
    "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
    "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
    "$$\n",
    "$$\n",
    "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
    "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
    "$$\n",
    "$$\n",
    "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
    "h_t =  o \\odot tanh(c_t) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.068954Z",
     "start_time": "2021-04-02T00:05:13.971286Z"
    },
    "id": "SMuQmjm4t4ym"
   },
   "outputs": [],
   "source": [
    "def init_h0_c0(num_objects, hidden_size, some_existing_tensor):\n",
    "    \"\"\"\n",
    "    return h0 and c0, use some_existing_tensor.new_zeros() to gen them\n",
    "    h0 shape: num_objects x hidden_size\n",
    "    c0 shape: num_objects x hidden_size\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    h_0 = some_existing_tensor.new_zeros(num_objects, hidden_size)\n",
    "    c_0 = some_existing_tensor.new_zeros(num_objects, hidden_size)\n",
    "    return h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.131347Z",
     "start_time": "2021-04-02T00:05:14.071577Z"
    },
    "id": "JBKCQbltt4yn"
   },
   "outputs": [],
   "source": [
    "def gen_dropout_mask(input_size, hidden_size, is_training, p, some_existing_tensor):\n",
    "    \"\"\"\n",
    "    is_training: if True, gen masks from Bernoulli\n",
    "                 if False, gen masks consisting of (1-p)\n",
    "    \n",
    "    return dropout masks of size input_size, hidden_size if p is not None\n",
    "    return one masks if p is None\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if p is None:\n",
    "        m_x = some_existing_tensor.new_ones(input_size)\n",
    "        h_x = some_existing_tensor.new_ones(hidden_size)\n",
    "        return m_x, h_x\n",
    "    if is_training:\n",
    "        m_x = torch.bernoulli((1-p) * some_existing_tensor.new_ones(input_size))\n",
    "        h_x = torch.bernoulli((1-p) * some_existing_tensor.new_ones(hidden_size))\n",
    "    else:\n",
    "        m_x = (1-p) * some_existing_tensor.new_ones(input_size)\n",
    "        h_x = (1-p) * some_existing_tensor.new_ones(hidden_size)\n",
    "    return m_x, h_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T21:09:12.282613Z",
     "start_time": "2021-04-01T21:09:12.256019Z"
    },
    "id": "TKs0H-7Et4yn"
   },
   "source": [
    "Допишите класс-обёртку над LSTMCell для реализации Variational Dropout. **Используйте только цикл по времени**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb8FbvRut4yn"
   },
   "source": [
    "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.190066Z",
     "start_time": "2021-04-02T00:05:14.132804Z"
    },
    "id": "fIVmFdPct4yo"
   },
   "outputs": [],
   "source": [
    "class RNNLayer(torch.nn.Module) :\n",
    "    def __init__(self, input_size, hidden_size, dropout=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize h_0, c_0\n",
    "        # YOUR CODE HERE\n",
    "        h0, c0 = init_h0_c0(x.size(1), self.hidden_size, x)\n",
    "        # x[max_length, batch_size, embedding_dim]\n",
    "        # h0, c0, h_t, c_t[batch_size, hidden_dim]\n",
    "        \n",
    "        # Gen masks for input and hidden state\n",
    "        # YOUR CODE HERE\n",
    "        m_x, h_x = gen_dropout_mask(self.input_size, self.hidden_size,\n",
    "                                    self.training, self.dropout, x)\n",
    "        #m_x[embedding_dim]\n",
    "        #h_x[hidden_dim]\n",
    "\n",
    "        # Implement recurrent logic and return what nn.LSTM returns\n",
    "        # Do not forget to apply generated dropout masks!\n",
    "        # YOUR CODE HERE\n",
    "        out = []\n",
    "        h_t, c_t = h0, c0\n",
    "        for t in range(x.size(0)):\n",
    "            h_t, c_t = self.rnn_cell(x[t]*m_x, (h_t*h_x, c_t))\n",
    "            m_x, h_x = gen_dropout_mask(self.input_size, self.hidden_size,\n",
    "                                    self.training, self.dropout, x)\n",
    "            out.append(h_t)\n",
    "        return torch.stack(out), (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acarUHS3t4yo"
   },
   "source": [
    "Протестируйте реализованную модель с выключенным дропаутом (слой `RNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Сильно ли оно увеличилось по сравнению с `torch.nn.LSTM` (LSTM \"из коробки\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT00SKZyt4yo"
   },
   "source": [
    "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T22:04:19.104557Z",
     "start_time": "2021-04-01T21:50:02.992858Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IicPF1zHt4yp",
    "outputId": "c96274cb-c143-4d96-f02e-7081488f7e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 1.992/1.997. Accuracy (Train/Test): 0.238/0.244\n",
      "Epoch: 2/15. Loss (Train/Test): 1.772/1.800. Accuracy (Train/Test): 0.333/0.329\n",
      "Epoch: 3/15. Loss (Train/Test): 1.670/1.727. Accuracy (Train/Test): 0.359/0.344\n",
      "Epoch: 4/15. Loss (Train/Test): 1.569/1.652. Accuracy (Train/Test): 0.383/0.347\n",
      "Epoch: 5/15. Loss (Train/Test): 1.484/1.605. Accuracy (Train/Test): 0.415/0.384\n",
      "Epoch: 6/15. Loss (Train/Test): 1.410/1.580. Accuracy (Train/Test): 0.444/0.388\n",
      "Epoch: 7/15. Loss (Train/Test): 1.371/1.592. Accuracy (Train/Test): 0.459/0.396\n",
      "Epoch: 8/15. Loss (Train/Test): 1.320/1.580. Accuracy (Train/Test): 0.484/0.390\n",
      "Epoch: 9/15. Loss (Train/Test): 1.256/1.592. Accuracy (Train/Test): 0.507/0.390\n",
      "Epoch: 10/15. Loss (Train/Test): 1.178/1.618. Accuracy (Train/Test): 0.540/0.388\n",
      "Epoch: 11/15. Loss (Train/Test): 1.118/1.652. Accuracy (Train/Test): 0.569/0.384\n",
      "Epoch: 12/15. Loss (Train/Test): 1.055/1.689. Accuracy (Train/Test): 0.597/0.381\n",
      "Epoch: 13/15. Loss (Train/Test): 0.977/1.795. Accuracy (Train/Test): 0.630/0.364\n",
      "Epoch: 14/15. Loss (Train/Test): 0.889/1.868. Accuracy (Train/Test): 0.670/0.371\n",
      "Epoch: 15/15. Loss (Train/Test): 0.827/1.976. Accuracy (Train/Test): 0.694/0.365\n",
      "working time is 10m 45s\n"
     ]
    }
   ],
   "source": [
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=RNNLayer, dropout=None \n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_vd_no_drop, train_accuracies_vd_no_drop, test_losses_vd_no_drop, test_accuracies_vd_no_drop = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWeS3-pQ1Tq8"
   },
   "source": [
    "Время обучения данной модели 5 раз больше, чем у LSTM \"из коробки\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5iVeUmVt4yp"
   },
   "source": [
    "Протестируйте полученную модель с `dropout=0.25`, вновь замерив время обучения. Получилось ли побороть переобучение? Сильно ли дольше обучается данная модель по сравнению с предыдущей? (доп. время тратится на генерацию масок дропаута)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T22:18:28.301613Z",
     "start_time": "2021-04-01T22:04:19.107850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRRSIJCNt4yp",
    "outputId": "c901b892-633f-4b00-f196-734bbeb7746b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 1.989/1.991. Accuracy (Train/Test): 0.252/0.253\n",
      "Epoch: 2/15. Loss (Train/Test): 1.777/1.791. Accuracy (Train/Test): 0.329/0.334\n",
      "Epoch: 3/15. Loss (Train/Test): 1.663/1.696. Accuracy (Train/Test): 0.358/0.356\n",
      "Epoch: 4/15. Loss (Train/Test): 1.577/1.631. Accuracy (Train/Test): 0.384/0.376\n",
      "Epoch: 5/15. Loss (Train/Test): 1.543/1.620. Accuracy (Train/Test): 0.399/0.376\n",
      "Epoch: 6/15. Loss (Train/Test): 1.483/1.572. Accuracy (Train/Test): 0.421/0.382\n",
      "Epoch: 7/15. Loss (Train/Test): 1.440/1.544. Accuracy (Train/Test): 0.433/0.399\n",
      "Epoch: 8/15. Loss (Train/Test): 1.417/1.550. Accuracy (Train/Test): 0.443/0.392\n",
      "Epoch: 9/15. Loss (Train/Test): 1.379/1.523. Accuracy (Train/Test): 0.460/0.403\n",
      "Epoch: 10/15. Loss (Train/Test): 1.349/1.533. Accuracy (Train/Test): 0.472/0.400\n",
      "Epoch: 11/15. Loss (Train/Test): 1.323/1.518. Accuracy (Train/Test): 0.478/0.412\n",
      "Epoch: 12/15. Loss (Train/Test): 1.295/1.517. Accuracy (Train/Test): 0.490/0.406\n",
      "Epoch: 13/15. Loss (Train/Test): 1.276/1.535. Accuracy (Train/Test): 0.497/0.408\n",
      "Epoch: 14/15. Loss (Train/Test): 1.255/1.531. Accuracy (Train/Test): 0.510/0.400\n",
      "Epoch: 15/15. Loss (Train/Test): 1.224/1.527. Accuracy (Train/Test): 0.520/0.402\n",
      "working time is 12m 47s\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=RNNLayer, dropout=0.25\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_vd_drop, train_accuracies_vd_drop, test_losses_vd_drop, test_accuracies_vd_drop = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJNrz_GG3A8e"
   },
   "source": [
    "Как видно, данная модель лучше справляется с переобучением. Данная обучается немного дольше по сравнению с предыдущей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5ph3X-ct4yq"
   },
   "source": [
    "## Реализация дропаута по статье Гала и Гарамани. Дубль 2 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMUDESskt4yq"
   },
   "source": [
    "<начало взлома pytorch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9A7wqRYt4yq"
   },
   "source": [
    "При разворачивании цикла по времени средствами python обучение рекуррентной нейросети сильно замедляется. Однако для реализации дропаута Гала и Гарамани необязательно явно задавать в коде домножение нейронов на маски. Можно схитрить и обойтись использованием слоя `torch.nn.LSTM`: перед вызовом `forward` слоя `torch.nn.LSTM` подменять его веса на веса, домноженные по строкам на маски. А обучаемые веса хранить отдельно. Именно так этот дропаут реализован в библиотеке `fastai`, код из которой использован в ячейке ниже.\n",
    "\n",
    "Такой слой реализуется в виде обертки над `torch.nn.LSTM`. Допишите класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.286206Z",
     "start_time": "2021-04-02T00:05:14.191730Z"
    },
    "id": "24Vxkjt4t4yr"
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:06:54.953123Z",
     "start_time": "2021-04-02T02:06:54.917017Z"
    },
    "id": "7MSnbwS1t4ys"
   },
   "outputs": [],
   "source": [
    "class FastRNNLayer(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.0, layers_dropout=0.0, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.layers_dropout = layers_dropout\n",
    "        self.module = torch.nn.LSTM(input_size, hidden_size, dropout=layers_dropout, num_layers=num_layers)\n",
    "\n",
    "        self.layer_names = []\n",
    "        for layer_n in range(self.num_layers):\n",
    "            self.layer_names += [f'weight_hh_l{layer_n}', f'weight_ih_l{layer_n}']\n",
    "\n",
    "        for layer in self.layer_names:\n",
    "            # Get torch.nn.Parameter with weights from torch.nn.LSTM instance\n",
    "            w = getattr(self.module, layer)\n",
    "\n",
    "            # Remove it from model\n",
    "            delattr(self.module, layer)\n",
    "\n",
    "            # And create new torch.nn.Parameter with the same data but different name\n",
    "            self.register_parameter(f'{layer}_raw', torch.nn.Parameter(w.data))\n",
    "\n",
    "            # Note. In torch.nn.LSTM.forward parameter with name `layer` will be used\n",
    "            #     so we must initialize it using `layer_raw` before forward pass\n",
    "\n",
    "    def _setweights(self, x):\n",
    "        \"\"\"\n",
    "            Apply dropout to the raw weights.\n",
    "        \"\"\"\n",
    "        for layer in self.layer_names:\n",
    "            # Get torch.nn.Parameter with weights\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "\n",
    "            # Generate mask (use function gen_dropout_mask)\n",
    "            # YOUR CODE HERE\n",
    "            w_mask, _ = gen_dropout_mask(raw_w.size(1), 0, self.training, self.dropout, x)\n",
    "\n",
    "            # Apply dropout mask\n",
    "            # YOUR CODE HERE\n",
    "            masked_raw_w = raw_w * w_mask\n",
    "\n",
    "            # Set modified weights in its place\n",
    "            setattr(self.module, layer, masked_raw_w)\n",
    "\n",
    "    def forward(self, x, h_c=None):\n",
    "        \"\"\"\n",
    "        :param x: tensor containing the features of the input sequence.\n",
    "        :param Optional[Tuple[torch.tensor, torch.tensor]] h_c: initial hidden state and initial cell state\n",
    "        \"\"\"\n",
    "        with warnings.catch_warnings():\n",
    "            # To avoid the warning that comes because the weights aren't flattened.\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            # Set new weights of self.module and call its forward\n",
    "            # Pass h_c with x if it is not None. Otherwise pass only x\n",
    "            # YOUR CODE HERE\n",
    "            self._setweights(x)\n",
    "            if h_c is not None:\n",
    "                return self.module(x, h_c)\n",
    "            return self.module(x)\n",
    "            \n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'):\n",
    "            self.module.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV8wZ-WSt4ys"
   },
   "source": [
    "Протестируйте реализованную модель с выключенным дропаутом (слой `FastRNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Убедитесь, что модель выдаёт такое же качество, как и оригинальная реализация LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTwBJigdt4yt"
   },
   "source": [
    "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T22:25:23.843846Z",
     "start_time": "2021-04-01T22:22:43.059254Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TarXIa2Tt4yt",
    "outputId": "070dce1d-1f61-403a-83aa-72a96d276749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 1.942/1.947. Accuracy (Train/Test): 0.280/0.281\n",
      "Epoch: 2/15. Loss (Train/Test): 1.697/1.728. Accuracy (Train/Test): 0.352/0.344\n",
      "Epoch: 3/15. Loss (Train/Test): 1.569/1.634. Accuracy (Train/Test): 0.393/0.364\n",
      "Epoch: 4/15. Loss (Train/Test): 1.506/1.603. Accuracy (Train/Test): 0.410/0.385\n",
      "Epoch: 5/15. Loss (Train/Test): 1.437/1.575. Accuracy (Train/Test): 0.441/0.382\n",
      "Epoch: 6/15. Loss (Train/Test): 1.376/1.565. Accuracy (Train/Test): 0.455/0.395\n",
      "Epoch: 7/15. Loss (Train/Test): 1.338/1.560. Accuracy (Train/Test): 0.467/0.402\n",
      "Epoch: 8/15. Loss (Train/Test): 1.313/1.607. Accuracy (Train/Test): 0.489/0.382\n",
      "Epoch: 9/15. Loss (Train/Test): 1.205/1.625. Accuracy (Train/Test): 0.523/0.393\n",
      "Epoch: 10/15. Loss (Train/Test): 1.147/1.636. Accuracy (Train/Test): 0.558/0.378\n",
      "Epoch: 11/15. Loss (Train/Test): 1.077/1.697. Accuracy (Train/Test): 0.581/0.380\n",
      "Epoch: 12/15. Loss (Train/Test): 0.984/1.773. Accuracy (Train/Test): 0.623/0.379\n",
      "Epoch: 13/15. Loss (Train/Test): 0.908/1.827. Accuracy (Train/Test): 0.667/0.358\n",
      "Epoch: 14/15. Loss (Train/Test): 0.823/1.989. Accuracy (Train/Test): 0.693/0.369\n",
      "Epoch: 15/15. Loss (Train/Test): 0.742/2.037. Accuracy (Train/Test): 0.742/0.356\n",
      "working time is 2m 20s\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=FastRNNLayer, dropout=None \n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_vd2_no_drop, train_accuracies_vd2_no_drop, test_losses_vd2_no_drop, test_accuracies_vd2_no_drop = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i27fYDgxt4yu"
   },
   "source": [
    "Протестируйте полученный слой (вновь подставив его в `RNNClassifier` в качестве `rec_layer`) с `dropout=0.25`. Сравните время обучения с предыдущими моделями. Проследите, чтобы качество получилось такое же, как при первой реализации этого дропаута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T22:28:38.168777Z",
     "start_time": "2021-04-01T22:25:56.717326Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBKFVZ7t4yu",
    "outputId": "a009e8aa-db9f-4a7c-f69f-7af4b79dce92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 2.010/2.011. Accuracy (Train/Test): 0.229/0.228\n",
      "Epoch: 2/15. Loss (Train/Test): 1.836/1.844. Accuracy (Train/Test): 0.318/0.320\n",
      "Epoch: 3/15. Loss (Train/Test): 1.691/1.717. Accuracy (Train/Test): 0.357/0.349\n",
      "Epoch: 4/15. Loss (Train/Test): 1.603/1.643. Accuracy (Train/Test): 0.380/0.369\n",
      "Epoch: 5/15. Loss (Train/Test): 1.554/1.612. Accuracy (Train/Test): 0.397/0.380\n",
      "Epoch: 6/15. Loss (Train/Test): 1.499/1.569. Accuracy (Train/Test): 0.413/0.392\n",
      "Epoch: 7/15. Loss (Train/Test): 1.461/1.549. Accuracy (Train/Test): 0.428/0.397\n",
      "Epoch: 8/15. Loss (Train/Test): 1.433/1.534. Accuracy (Train/Test): 0.437/0.403\n",
      "Epoch: 9/15. Loss (Train/Test): 1.402/1.520. Accuracy (Train/Test): 0.451/0.409\n",
      "Epoch: 10/15. Loss (Train/Test): 1.380/1.522. Accuracy (Train/Test): 0.457/0.404\n",
      "Epoch: 11/15. Loss (Train/Test): 1.359/1.524. Accuracy (Train/Test): 0.464/0.406\n",
      "Epoch: 12/15. Loss (Train/Test): 1.336/1.515. Accuracy (Train/Test): 0.473/0.417\n",
      "Epoch: 13/15. Loss (Train/Test): 1.320/1.521. Accuracy (Train/Test): 0.483/0.408\n",
      "Epoch: 14/15. Loss (Train/Test): 1.294/1.511. Accuracy (Train/Test): 0.489/0.414\n",
      "Epoch: 15/15. Loss (Train/Test): 1.271/1.523. Accuracy (Train/Test): 0.498/0.413\n",
      "working time is 2m 20s\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=FastRNNLayer, dropout=0.25\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_vd2_drop, train_accuracies_vd2_drop, test_losses_vd2_drop, test_accuracies_vd2_drop = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70BndJzg53Yi"
   },
   "source": [
    "По результатам обучения можно отметить, что модели с реализацией дропаута в этом разделе имеют схожее качество с предыдущими, однако обучаются в несколько раз быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XfCDrqtt4yu"
   },
   "source": [
    "</конец взлома pytorch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC6HWSa5t4yv"
   },
   "source": [
    "## Реализация дропаута по статье Семениуты и др. (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETENiGSyt4yv"
   },
   "source": [
    "Перейдем к реализации дропаута для LSTM по статье [Semeniuta et al](http://www.aclweb.org/anthology/C16-1165). \n",
    "\n",
    "Этот метод применения дропаута не менее популярен, чем предыдущий. Его особенность состоит в том, что он придуман специально для гейтовых архитектур. В контексте LSTM этот дропаут накладывается только на информационный поток (m_h - маска дропаута):\n",
    "$$\n",
    "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
    "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
    "$$\n",
    "$$\n",
    "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
    "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
    "$$\n",
    "$$\n",
    "c_t = f \\odot c_{t-1} +  i \\odot g \\odot {\\bf m_h} \\quad\n",
    "h_t =  o \\odot tanh(c_t) \\nonumber\n",
    "$$\n",
    "На входы $x_t$ маска накладывается как в предыдущем дропауте. Впрочем, на входы маску можно наложить вообще до вызова рекуррентного слоя.\n",
    "\n",
    "Согласно статье, маска дропаута может быть как одинаковая, так и разная для всех моментов времени. Мы сделаем одинаковую для всех моментов времени.\n",
    "\n",
    "Для реализации этого дропаута можно: \n",
    "1. самостоятельно реализовать LSTM (интерфейса LSTMCell не хватит) \n",
    "2. снова воспользоваться трюком с установкой весов (но тут мы опираемся на свойство $tanh(0)=0$, к тому же, трюк в данном случае выглядит менее тривиально, чем с дропаутом Гала). \n",
    "\n",
    "Предлагается реализовать дропаут по сценарию 1. Допишите класс:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0OBBTfVt4yv"
   },
   "source": [
    "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.447201Z",
     "start_time": "2021-04-02T00:05:14.350457Z"
    },
    "id": "dJq7e_6Nt4yw"
   },
   "outputs": [],
   "source": [
    "class HandmadeLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n",
    "        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        \n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        \"\"\"\n",
    "        Initialization as in Pytorch. \n",
    "        Do not forget to call this method!\n",
    "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n",
    "        \"\"\"\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use functions init_h0_c0 and gen_dropout_masks defined above\n",
    "        # YOUR CODE HERE\n",
    "        h0, c0 = init_h0_c0(x.size(1), self.hidden_size, x)\n",
    "        m_x, h_x = gen_dropout_mask(self.input_size, self.hidden_size,\n",
    "                                    self.training, self.dropout, x)\n",
    "        # x[max_length, batch_size, embedding_dim]\n",
    "        # h0, c0, h_t, c_t[batch_size, hidden_dim]\n",
    "        # m_x[embedding_dim], h_x[hidden_dim]\n",
    "\n",
    "        # Implement recurrent logic to mimic torch.nn.LSTM\n",
    "        # Do not forget to apply dropout mask\n",
    "        # YOUR CODE HERE\n",
    "        out = []\n",
    "        h_t, c_t = h0, c0\n",
    "        for t in range(x.size(0)):\n",
    "            iofg = self.hidden_weights(h_t)+self.input_weights(x[t]*m_x) #iofg[batch_size, 4*hidden_dim]\n",
    "            i = torch.sigmoid(iofg[:, :self.hidden_size])\n",
    "            o = torch.sigmoid(iofg[:,self.hidden_size:2*self.hidden_size])\n",
    "            f = torch.sigmoid(iofg[:,2*self.hidden_size:3*self.hidden_size])\n",
    "            g = torch.tanh(iofg[..., 3*self.hidden_size:])\n",
    "            #i, o, f, g : torch.tensor([batch_size, hidden_dim])\n",
    "            c_t = f*c_t + i*g*h_x\n",
    "            h_t = o * torch.tanh(c_t)\n",
    "            out.append(h_t)\n",
    "        return torch.stack(out), (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjsLNSBTt4yw"
   },
   "source": [
    "Протестируйте вашу реализацию без дропаута (проконтролируйте качество и сравните время обучения с временем обучения `torch.nn.LSTM` и `RNNLayer`), а также с `dropout=0.25`. Сравните качество модели с таким дропаутом с качеством модели с дропаутом Гала и Гарамани."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUVHSn17t4yw"
   },
   "source": [
    "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4GgfO5dH0Jx",
    "outputId": "7aa110d9-441d-430f-b50f-558f39ba365e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 1.974/1.976. Accuracy (Train/Test): 0.270/0.272\n",
      "Epoch: 2/15. Loss (Train/Test): 1.690/1.722. Accuracy (Train/Test): 0.351/0.350\n",
      "Epoch: 3/15. Loss (Train/Test): 1.611/1.664. Accuracy (Train/Test): 0.375/0.353\n",
      "Epoch: 4/15. Loss (Train/Test): 1.518/1.609. Accuracy (Train/Test): 0.406/0.380\n",
      "Epoch: 5/15. Loss (Train/Test): 1.471/1.604. Accuracy (Train/Test): 0.420/0.368\n",
      "Epoch: 6/15. Loss (Train/Test): 1.389/1.564. Accuracy (Train/Test): 0.458/0.390\n",
      "Epoch: 7/15. Loss (Train/Test): 1.327/1.557. Accuracy (Train/Test): 0.479/0.396\n",
      "Epoch: 8/15. Loss (Train/Test): 1.275/1.607. Accuracy (Train/Test): 0.498/0.394\n",
      "Epoch: 9/15. Loss (Train/Test): 1.223/1.613. Accuracy (Train/Test): 0.525/0.379\n",
      "Epoch: 10/15. Loss (Train/Test): 1.145/1.642. Accuracy (Train/Test): 0.550/0.396\n",
      "Epoch: 11/15. Loss (Train/Test): 1.068/1.707. Accuracy (Train/Test): 0.584/0.383\n",
      "Epoch: 12/15. Loss (Train/Test): 0.998/1.749. Accuracy (Train/Test): 0.624/0.368\n",
      "Epoch: 13/15. Loss (Train/Test): 0.909/1.838. Accuracy (Train/Test): 0.656/0.374\n",
      "Epoch: 14/15. Loss (Train/Test): 0.835/1.926. Accuracy (Train/Test): 0.698/0.362\n",
      "Epoch: 15/15. Loss (Train/Test): 0.766/2.025. Accuracy (Train/Test): 0.722/0.363\n",
      "working time is 22m 3s\n"
     ]
    }
   ],
   "source": [
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=HandmadeLSTM, dropout=None\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_no_drop3, train_accuracies_no_drop3, test_losses_no_drop3, test_accuracies_no_drop3 = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dUomvAA7YMf",
    "outputId": "d800c385-4edc-4955-f75a-81c57aaba14e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15. Loss (Train/Test): 2.033/2.038. Accuracy (Train/Test): 0.205/0.202\n",
      "Epoch: 2/15. Loss (Train/Test): 2.003/2.010. Accuracy (Train/Test): 0.271/0.278\n",
      "Epoch: 3/15. Loss (Train/Test): 1.775/1.791. Accuracy (Train/Test): 0.335/0.338\n",
      "Epoch: 4/15. Loss (Train/Test): 1.677/1.703. Accuracy (Train/Test): 0.355/0.350\n",
      "Epoch: 5/15. Loss (Train/Test): 1.640/1.682. Accuracy (Train/Test): 0.364/0.359\n",
      "Epoch: 6/15. Loss (Train/Test): 1.600/1.656. Accuracy (Train/Test): 0.375/0.361\n",
      "Epoch: 7/15. Loss (Train/Test): 1.550/1.620. Accuracy (Train/Test): 0.395/0.373\n",
      "Epoch: 8/15. Loss (Train/Test): 1.519/1.601. Accuracy (Train/Test): 0.404/0.381\n",
      "Epoch: 9/15. Loss (Train/Test): 1.499/1.597. Accuracy (Train/Test): 0.417/0.383\n",
      "Epoch: 10/15. Loss (Train/Test): 1.476/1.578. Accuracy (Train/Test): 0.418/0.379\n",
      "Epoch: 11/15. Loss (Train/Test): 1.463/1.572. Accuracy (Train/Test): 0.420/0.395\n",
      "Epoch: 12/15. Loss (Train/Test): 1.426/1.561. Accuracy (Train/Test): 0.437/0.401\n",
      "Epoch: 13/15. Loss (Train/Test): 1.413/1.554. Accuracy (Train/Test): 0.435/0.405\n",
      "Epoch: 14/15. Loss (Train/Test): 1.421/1.577. Accuracy (Train/Test): 0.446/0.398\n",
      "Epoch: 15/15. Loss (Train/Test): 1.362/1.538. Accuracy (Train/Test): 0.464/0.401\n",
      "working time is 21m 55s\n"
     ]
    }
   ],
   "source": [
    "model = RNNClassifier(\n",
    "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10,\n",
    "    vocab=vocab, rec_layer=HandmadeLSTM, dropout=0.25\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "train_losses_drop3, train_accuracies_drop3, test_losses_drop3, test_accuracies_drop3 = train(\n",
    "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
    ")\n",
    "\n",
    "all_time = time.perf_counter() - t_start\n",
    "print(f'working time is {all_time//60:.0f}m {all_time%60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7m1arAsZk65"
   },
   "source": [
    "Точность на тесте у данных моделей схожа с качеством модели с дропаутом Гала и Гарамани, время обучения дольше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T23:33:28.831346Z",
     "start_time": "2021-04-01T23:33:28.810453Z"
    },
    "id": "ZWd1iNuft4yx"
   },
   "source": [
    "## Сравнение всех предложенных моделей. (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T23:48:05.361634Z",
     "start_time": "2021-04-01T23:48:05.333901Z"
    },
    "id": "R0FIfjIQt4yy"
   },
   "source": [
    "Используя замеры времени заполните табличку с временем работы четырёх реализованных моделей в следующей ячейке:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUcbVIsdvvER"
   },
   "source": [
    "| dropout\\model | torch.nn.LSTM | RNNLayer | FastRNNLayer | HandmadeLSTM |\n",
    "|---------------|---------------|----------|--------------|--------------|\n",
    "|      None     | 2m 14s        | 10m 45s  | 2m 20s       | 22m 3s       |\n",
    "|      0.25     | ______        | 12m 47s  | 2m 20s       | 21m 55s      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyFUCIR7vHwY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.722913Z",
     "start_time": "2021-04-02T00:05:14.448857Z"
    },
    "id": "bFiBVpiut4yy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqYd7jMct4yz"
   },
   "source": [
    "Крайне желательно рисовать графики в векторном формате. \n",
    "\n",
    "Если по каким-то причинам, отрисовка не будет работать, закомментируйте следующую ячейку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:05:14.745238Z",
     "start_time": "2021-04-02T00:05:14.724188Z"
    },
    "id": "QMY4V63Dt4yz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjPPKRAit4y0"
   },
   "source": [
    "Нарисуйте два графика -- функция потерь и качество на обучающей и тестовой выборке для всех 7 моделей обученных выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "m40FmTtORH9H",
    "outputId": "42daa1ba-389c-49ad-ce19-3a5458fd7909"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"712.15625pt\" version=\"1.1\" viewBox=\"0 0 712.703125 712.15625\" width=\"712.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 712.15625 \n",
       "L 712.703125 712.15625 \n",
       "L 712.703125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 312 \n",
       "L 705.503125 312 \n",
       "L 705.503125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 312 \n",
       "L 60.803125 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mbc15c1c691\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"60.803125\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(57.621875 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 148.517411 312 \n",
       "L 148.517411 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.517411\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(145.336161 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 236.231696 312 \n",
       "L 236.231696 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.231696\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 4 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(233.050446 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 323.945982 312 \n",
       "L 323.945982 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.945982\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 6 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(320.764732 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 411.660268 312 \n",
       "L 411.660268 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"411.660268\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 8 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(408.479018 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 499.374554 312 \n",
       "L 499.374554 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"499.374554\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(493.012054 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 587.088839 312 \n",
       "L 587.088839 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"587.088839\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 12 -->\n",
       "      <g transform=\"translate(580.726339 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 674.803125 312 \n",
       "L 674.803125 7.2 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"674.803125\" xlink:href=\"#mbc15c1c691\" y=\"312\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 14 -->\n",
       "      <g transform=\"translate(668.440625 326.598437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- Epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(352.492187 340.276562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 285.836814 \n",
       "L 705.503125 285.836814 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"ma2d6825854\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"285.836814\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(7.2 289.636033)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 243.073484 \n",
       "L 705.503125 243.073484 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"243.073484\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 246.872703)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 200.310154 \n",
       "L 705.503125 200.310154 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"200.310154\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.2 -->\n",
       "      <g transform=\"translate(7.2 204.109372)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 157.546823 \n",
       "L 705.503125 157.546823 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"157.546823\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.4 -->\n",
       "      <g transform=\"translate(7.2 161.346042)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 114.783493 \n",
       "L 705.503125 114.783493 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"114.783493\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 1.6 -->\n",
       "      <g transform=\"translate(7.2 118.582712)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 72.020163 \n",
       "L 705.503125 72.020163 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"72.020163\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 1.8 -->\n",
       "      <g transform=\"translate(7.2 75.819382)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path clip-path=\"url(#p018823bbda)\" d=\"M 30.103125 29.256833 \n",
       "L 705.503125 29.256833 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"29.256833\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(7.2 33.056051)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 52.341903 \n",
       "L 104.660268 84.218436 \n",
       "L 148.517411 109.86731 \n",
       "L 192.374554 126.505261 \n",
       "L 236.231696 143.941168 \n",
       "L 280.088839 149.580288 \n",
       "L 323.945982 167.370976 \n",
       "L 367.803125 174.323617 \n",
       "L 411.660268 187.952064 \n",
       "L 455.517411 200.732393 \n",
       "L 499.374554 214.925522 \n",
       "L 543.231696 230.868262 \n",
       "L 587.088839 245.880261 \n",
       "L 630.945982 262.424935 \n",
       "L 674.803125 281.382251 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_32\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 31.560242 \n",
       "L 104.660268 77.030889 \n",
       "L 148.517411 101.219936 \n",
       "L 192.374554 119.658144 \n",
       "L 236.231696 126.971709 \n",
       "L 280.088839 139.728383 \n",
       "L 323.945982 148.923362 \n",
       "L 367.803125 153.863933 \n",
       "L 411.660268 162.062932 \n",
       "L 455.517411 168.386404 \n",
       "L 499.374554 173.939652 \n",
       "L 543.231696 179.975151 \n",
       "L 587.088839 184.011833 \n",
       "L 630.945982 188.581004 \n",
       "L 674.803125 195.082032 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_33\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 30.918532 \n",
       "L 104.660268 77.984965 \n",
       "L 148.517411 99.818987 \n",
       "L 192.374554 121.321654 \n",
       "L 236.231696 139.650311 \n",
       "L 280.088839 155.422122 \n",
       "L 323.945982 163.791642 \n",
       "L 367.803125 174.586892 \n",
       "L 411.660268 188.420245 \n",
       "L 455.517411 205.057202 \n",
       "L 499.374554 217.90347 \n",
       "L 543.231696 231.228395 \n",
       "L 587.088839 248.079089 \n",
       "L 630.945982 266.890214 \n",
       "L 674.803125 280.115808 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_34\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 27.019975 \n",
       "L 104.660268 64.339237 \n",
       "L 148.517411 95.427525 \n",
       "L 192.374554 114.14341 \n",
       "L 236.231696 124.587219 \n",
       "L 280.088839 136.365119 \n",
       "L 323.945982 144.597304 \n",
       "L 367.803125 150.555266 \n",
       "L 411.660268 157.200281 \n",
       "L 455.517411 161.751814 \n",
       "L 499.374554 166.38978 \n",
       "L 543.231696 171.229847 \n",
       "L 587.088839 174.570885 \n",
       "L 630.945982 180.285733 \n",
       "L 674.803125 185.185419 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_35\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 41.671675 \n",
       "L 104.660268 93.989006 \n",
       "L 148.517411 121.393354 \n",
       "L 192.374554 134.798671 \n",
       "L 236.231696 149.583653 \n",
       "L 280.088839 162.743002 \n",
       "L 323.945982 170.755294 \n",
       "L 367.803125 176.102439 \n",
       "L 411.660268 199.245879 \n",
       "L 455.517411 211.658402 \n",
       "L 499.374554 226.620149 \n",
       "L 543.231696 246.524086 \n",
       "L 587.088839 262.662887 \n",
       "L 630.945982 281.016893 \n",
       "L 674.803125 298.145455 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_36\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 22.293511 \n",
       "L 104.660268 28.70566 \n",
       "L 148.517411 77.428924 \n",
       "L 192.374554 98.246652 \n",
       "L 236.231696 106.2866 \n",
       "L 280.088839 114.762077 \n",
       "L 323.945982 125.38018 \n",
       "L 367.803125 132.036232 \n",
       "L 411.660268 136.334405 \n",
       "L 455.517411 141.394416 \n",
       "L 499.374554 144.080389 \n",
       "L 543.231696 151.918974 \n",
       "L 587.088839 154.733029 \n",
       "L 630.945982 152.95459 \n",
       "L 674.803125 165.579792 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_37\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 34.813649 \n",
       "L 104.660268 95.521018 \n",
       "L 148.517411 112.505262 \n",
       "L 192.374554 132.239735 \n",
       "L 236.231696 142.334321 \n",
       "L 280.088839 159.98617 \n",
       "L 323.945982 173.082077 \n",
       "L 367.803125 184.352747 \n",
       "L 411.660268 195.420347 \n",
       "L 455.517411 212.161859 \n",
       "L 499.374554 228.575329 \n",
       "L 543.231696 243.56528 \n",
       "L 587.088839 262.529618 \n",
       "L 630.945982 278.432264 \n",
       "L 674.803125 293.152657 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_38\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 50.38267 \n",
       "L 104.660268 79.023639 \n",
       "L 148.517411 98.168171 \n",
       "L 192.374554 108.947313 \n",
       "L 236.231696 117.792737 \n",
       "L 280.088839 118.272668 \n",
       "L 323.945982 122.234642 \n",
       "L 367.803125 119.947851 \n",
       "L 411.660268 119.25756 \n",
       "L 455.517411 111.087211 \n",
       "L 499.374554 105.286108 \n",
       "L 543.231696 96.149372 \n",
       "L 587.088839 76.003405 \n",
       "L 630.945982 69.606448 \n",
       "L 674.803125 49.032878 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_39\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 31.12744 \n",
       "L 104.660268 73.95621 \n",
       "L 148.517411 94.334534 \n",
       "L 192.374554 108.258143 \n",
       "L 236.231696 110.508714 \n",
       "L 280.088839 120.687056 \n",
       "L 323.945982 126.818469 \n",
       "L 367.803125 125.429807 \n",
       "L 411.660268 131.183168 \n",
       "L 455.517411 129.035981 \n",
       "L 499.374554 132.330833 \n",
       "L 543.231696 132.514022 \n",
       "L 587.088839 128.592957 \n",
       "L 630.945982 129.539158 \n",
       "L 674.803125 130.336298 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_40\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 29.88516 \n",
       "L 104.660268 72.054991 \n",
       "L 148.517411 87.596484 \n",
       "L 192.374554 103.649209 \n",
       "L 236.231696 113.776599 \n",
       "L 280.088839 119.028262 \n",
       "L 323.945982 116.517959 \n",
       "L 367.803125 118.970274 \n",
       "L 411.660268 116.464712 \n",
       "L 455.517411 110.958364 \n",
       "L 499.374554 103.570091 \n",
       "L 543.231696 95.797064 \n",
       "L 587.088839 73.036442 \n",
       "L 630.945982 57.430105 \n",
       "L 674.803125 34.397364 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_41\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 26.985973 \n",
       "L 104.660268 62.509565 \n",
       "L 148.517411 89.843665 \n",
       "L 192.374554 105.51635 \n",
       "L 236.231696 112.152164 \n",
       "L 280.088839 121.468801 \n",
       "L 323.945982 125.656786 \n",
       "L 367.803125 128.922173 \n",
       "L 411.660268 131.874326 \n",
       "L 455.517411 131.403214 \n",
       "L 499.374554 130.944872 \n",
       "L 543.231696 132.915957 \n",
       "L 587.088839 131.669268 \n",
       "L 630.945982 133.72885 \n",
       "L 674.803125 131.308064 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_42\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 40.648091 \n",
       "L 104.660268 87.497664 \n",
       "L 148.517411 107.550519 \n",
       "L 192.374554 114.054887 \n",
       "L 236.231696 120.177889 \n",
       "L 280.088839 122.197734 \n",
       "L 323.945982 123.345526 \n",
       "L 367.803125 113.332199 \n",
       "L 411.660268 109.383428 \n",
       "L 455.517411 107.069798 \n",
       "L 499.374554 94.042711 \n",
       "L 543.231696 77.796169 \n",
       "L 587.088839 66.262555 \n",
       "L 630.945982 31.51013 \n",
       "L 674.803125 21.290624 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_43\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 21.054545 \n",
       "L 104.660268 27.114386 \n",
       "L 148.517411 73.961053 \n",
       "L 192.374554 92.717593 \n",
       "L 236.231696 97.172293 \n",
       "L 280.088839 102.90065 \n",
       "L 323.945982 110.465051 \n",
       "L 367.803125 114.512031 \n",
       "L 411.660268 115.364687 \n",
       "L 455.517411 119.542501 \n",
       "L 499.374554 120.686903 \n",
       "L 543.231696 123.08559 \n",
       "L 587.088839 124.65163 \n",
       "L 630.945982 119.774093 \n",
       "L 674.803125 127.965344 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_44\">\n",
       "    <path clip-path=\"url(#p018823bbda)\" d=\"M 60.803125 34.448571 \n",
       "L 104.660268 88.794897 \n",
       "L 148.517411 101.205815 \n",
       "L 192.374554 112.780976 \n",
       "L 236.231696 113.846617 \n",
       "L 280.088839 122.377278 \n",
       "L 323.945982 123.950786 \n",
       "L 367.803125 113.255579 \n",
       "L 411.660268 112.021303 \n",
       "L 455.517411 105.860731 \n",
       "L 499.374554 91.914921 \n",
       "L 543.231696 82.958238 \n",
       "L 587.088839 63.813298 \n",
       "L 630.945982 45.067591 \n",
       "L 674.803125 23.909663 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 312 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 705.503125 312 \n",
       "L 705.503125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 312 \n",
       "L 705.503125 312 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 705.503125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 37.103125 307 \n",
       "L 160.320313 307 \n",
       "Q 162.320313 307 162.320313 305 \n",
       "L 162.320313 100.50625 \n",
       "Q 162.320313 98.50625 160.320313 98.50625 \n",
       "L 37.103125 98.50625 \n",
       "Q 35.103125 98.50625 35.103125 100.50625 \n",
       "L 35.103125 305 \n",
       "Q 35.103125 307 37.103125 307 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_45\">\n",
       "     <path d=\"M 39.103125 106.604687 \n",
       "L 59.103125 106.604687 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_46\"/>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- Base -->\n",
       "     <defs>\n",
       "      <path d=\"M 19.671875 34.8125 \n",
       "L 19.671875 8.109375 \n",
       "L 35.5 8.109375 \n",
       "Q 43.453125 8.109375 47.28125 11.40625 \n",
       "Q 51.125 14.703125 51.125 21.484375 \n",
       "Q 51.125 28.328125 47.28125 31.5625 \n",
       "Q 43.453125 34.8125 35.5 34.8125 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 42.828125 \n",
       "L 34.28125 42.828125 \n",
       "Q 41.5 42.828125 45.03125 45.53125 \n",
       "Q 48.578125 48.25 48.578125 53.8125 \n",
       "Q 48.578125 59.328125 45.03125 62.0625 \n",
       "Q 41.5 64.796875 34.28125 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 35.015625 72.90625 \n",
       "Q 46.296875 72.90625 52.390625 68.21875 \n",
       "Q 58.5 63.53125 58.5 54.890625 \n",
       "Q 58.5 48.1875 55.375 44.234375 \n",
       "Q 52.25 40.28125 46.1875 39.3125 \n",
       "Q 53.46875 37.75 57.5 32.78125 \n",
       "Q 61.53125 27.828125 61.53125 20.40625 \n",
       "Q 61.53125 10.640625 54.890625 5.3125 \n",
       "Q 48.25 0 35.984375 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-66\"/>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 110.104687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use x=\"68.603516\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"129.882812\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"181.982422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_47\">\n",
       "     <path d=\"M 39.103125 121.282812 \n",
       "L 59.103125 121.282812 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_48\"/>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- VarDropCheck -->\n",
       "     <defs>\n",
       "      <path d=\"M 28.609375 0 \n",
       "L 0.78125 72.90625 \n",
       "L 11.078125 72.90625 \n",
       "L 34.1875 11.53125 \n",
       "L 57.328125 72.90625 \n",
       "L 67.578125 72.90625 \n",
       "L 39.796875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-86\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "      <path d=\"M 19.671875 64.796875 \n",
       "L 19.671875 8.109375 \n",
       "L 31.59375 8.109375 \n",
       "Q 46.6875 8.109375 53.6875 14.9375 \n",
       "Q 60.6875 21.78125 60.6875 36.53125 \n",
       "Q 60.6875 51.171875 53.6875 57.984375 \n",
       "Q 46.6875 64.796875 31.59375 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 30.078125 72.90625 \n",
       "Q 51.265625 72.90625 61.171875 64.09375 \n",
       "Q 71.09375 55.28125 71.09375 36.53125 \n",
       "Q 71.09375 17.671875 61.125 8.828125 \n",
       "Q 51.171875 0 30.078125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-68\"/>\n",
       "      <path d=\"M 64.40625 67.28125 \n",
       "L 64.40625 56.890625 \n",
       "Q 59.421875 61.53125 53.78125 63.8125 \n",
       "Q 48.140625 66.109375 41.796875 66.109375 \n",
       "Q 29.296875 66.109375 22.65625 58.46875 \n",
       "Q 16.015625 50.828125 16.015625 36.375 \n",
       "Q 16.015625 21.96875 22.65625 14.328125 \n",
       "Q 29.296875 6.6875 41.796875 6.6875 \n",
       "Q 48.140625 6.6875 53.78125 8.984375 \n",
       "Q 59.421875 11.28125 64.40625 15.921875 \n",
       "L 64.40625 5.609375 \n",
       "Q 59.234375 2.09375 53.4375 0.328125 \n",
       "Q 47.65625 -1.421875 41.21875 -1.421875 \n",
       "Q 24.65625 -1.421875 15.125 8.703125 \n",
       "Q 5.609375 18.84375 5.609375 36.375 \n",
       "Q 5.609375 53.953125 15.125 64.078125 \n",
       "Q 24.65625 74.21875 41.21875 74.21875 \n",
       "Q 47.75 74.21875 53.53125 72.484375 \n",
       "Q 59.328125 70.75 64.40625 67.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-67\"/>\n",
       "      <path d=\"M 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 31.109375 \n",
       "L 44.921875 54.6875 \n",
       "L 56.390625 54.6875 \n",
       "L 27.390625 29.109375 \n",
       "L 57.625 0 \n",
       "L 45.90625 0 \n",
       "L 18.109375 26.703125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-107\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 124.782812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"403.574219\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"473.398438\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"536.777344\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"598.300781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"653.28125\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_49\">\n",
       "     <path d=\"M 39.103125 135.960937 \n",
       "L 59.103125 135.960937 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_50\"/>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- VarDrop -->\n",
       "     <g transform=\"translate(67.103125 139.460937)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_51\">\n",
       "     <path d=\"M 39.103125 150.639062 \n",
       "L 59.103125 150.639062 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_52\"/>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- FastVarDropCheck -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 51.703125 72.90625 \n",
       "L 51.703125 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.109375 \n",
       "L 48.578125 43.109375 \n",
       "L 48.578125 34.8125 \n",
       "L 19.671875 34.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\"/>\n",
       "      <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 154.139062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"604.556641\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"674.380859\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"737.759766\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"799.283203\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"854.263672\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_53\">\n",
       "     <path d=\"M 39.103125 165.317187 \n",
       "L 59.103125 165.317187 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_54\"/>\n",
       "    <g id=\"text_21\">\n",
       "     <!-- FastVarDrop -->\n",
       "     <g transform=\"translate(67.103125 168.817187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_55\">\n",
       "     <path d=\"M 39.103125 179.995312 \n",
       "L 59.103125 179.995312 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_56\"/>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- HandmadeCheck -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 43.015625 \n",
       "L 55.515625 43.015625 \n",
       "L 55.515625 72.90625 \n",
       "L 65.375 72.90625 \n",
       "L 65.375 0 \n",
       "L 55.515625 0 \n",
       "L 55.515625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-72\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 183.495312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"616.845703\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"680.224609\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"741.748047\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"796.728516\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_57\">\n",
       "     <path d=\"M 39.103125 194.673437 \n",
       "L 59.103125 194.673437 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_58\"/>\n",
       "    <g id=\"text_23\">\n",
       "     <!-- Handmade -->\n",
       "     <g transform=\"translate(67.103125 198.173437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_59\">\n",
       "     <path d=\"M 39.103125 209.351562 \n",
       "L 59.103125 209.351562 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_60\"/>\n",
       "    <g id=\"text_24\">\n",
       "     <!-- Base -->\n",
       "     <g transform=\"translate(67.103125 212.851562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use x=\"68.603516\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"129.882812\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"181.982422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_61\">\n",
       "     <path d=\"M 39.103125 224.029687 \n",
       "L 59.103125 224.029687 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_62\"/>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- VarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 227.529687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"403.574219\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"473.398438\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"536.777344\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"598.300781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"653.28125\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_63\">\n",
       "     <path d=\"M 39.103125 238.707812 \n",
       "L 59.103125 238.707812 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_64\"/>\n",
       "    <g id=\"text_26\">\n",
       "     <!-- VarDrop -->\n",
       "     <g transform=\"translate(67.103125 242.207812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_65\">\n",
       "     <path d=\"M 39.103125 253.385937 \n",
       "L 59.103125 253.385937 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_66\"/>\n",
       "    <g id=\"text_27\">\n",
       "     <!-- FastVarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 256.885937)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"604.556641\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"674.380859\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"737.759766\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"799.283203\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"854.263672\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_67\">\n",
       "     <path d=\"M 39.103125 268.064062 \n",
       "L 59.103125 268.064062 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_68\"/>\n",
       "    <g id=\"text_28\">\n",
       "     <!-- FastVarDrop -->\n",
       "     <g transform=\"translate(67.103125 271.564062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_69\">\n",
       "     <path d=\"M 39.103125 282.742187 \n",
       "L 59.103125 282.742187 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_70\"/>\n",
       "    <g id=\"text_29\">\n",
       "     <!-- HandmadeCheck -->\n",
       "     <g transform=\"translate(67.103125 286.242187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"616.845703\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"680.224609\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"741.748047\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"796.728516\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_71\">\n",
       "     <path d=\"M 39.103125 297.420312 \n",
       "L 59.103125 297.420312 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_72\"/>\n",
       "    <g id=\"text_30\">\n",
       "     <!-- Handmade -->\n",
       "     <g transform=\"translate(67.103125 300.920312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 30.103125 674.6 \n",
       "L 705.503125 674.6 \n",
       "L 705.503125 369.8 \n",
       "L 30.103125 369.8 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_73\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 674.6 \n",
       "L 60.803125 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_74\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"60.803125\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(57.621875 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_75\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 148.517411 674.6 \n",
       "L 148.517411 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_76\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.517411\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_32\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(145.336161 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_77\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 236.231696 674.6 \n",
       "L 236.231696 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_78\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.231696\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(233.050446 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_79\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 323.945982 674.6 \n",
       "L 323.945982 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_80\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.945982\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(320.764732 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_81\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 411.660268 674.6 \n",
       "L 411.660268 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_82\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"411.660268\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(408.479018 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_83\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 499.374554 674.6 \n",
       "L 499.374554 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_84\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"499.374554\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(493.012054 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_85\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 587.088839 674.6 \n",
       "L 587.088839 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_86\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"587.088839\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_37\">\n",
       "      <!-- 12 -->\n",
       "      <g transform=\"translate(580.726339 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_87\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 674.803125 674.6 \n",
       "L 674.803125 369.8 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_88\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"674.803125\" xlink:href=\"#mbc15c1c691\" y=\"674.6\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_38\">\n",
       "      <!-- 14 -->\n",
       "      <g transform=\"translate(668.440625 689.198437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_39\">\n",
       "     <!-- Epoch -->\n",
       "     <g transform=\"translate(352.492187 702.876562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_89\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 661.812845 \n",
       "L 705.503125 661.812845 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_90\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"661.812845\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_40\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 665.612064)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_91\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 610.495911 \n",
       "L 705.503125 610.495911 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_92\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"610.495911\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_41\">\n",
       "      <!-- 0.3 -->\n",
       "      <defs>\n",
       "       <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(7.2 614.295129)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_93\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 559.178976 \n",
       "L 705.503125 559.178976 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_94\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"559.178976\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_42\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 562.978195)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_95\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 507.862042 \n",
       "L 705.503125 507.862042 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_96\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"507.862042\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_43\">\n",
       "      <!-- 0.5 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(7.2 511.661261)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_97\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 456.545108 \n",
       "L 705.503125 456.545108 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_98\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"456.545108\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_44\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 460.344327)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_99\">\n",
       "      <path clip-path=\"url(#p28e2ef4948)\" d=\"M 30.103125 405.228174 \n",
       "L 705.503125 405.228174 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_100\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma2d6825854\" y=\"405.228174\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_45\">\n",
       "      <!-- 0.7 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(7.2 409.027392)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_101\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 610.064853 \n",
       "L 104.660268 589.497021 \n",
       "L 148.517411 575.066708 \n",
       "L 192.374554 562.894333 \n",
       "L 236.231696 543.085998 \n",
       "L 280.088839 538.036406 \n",
       "L 323.945982 524.078193 \n",
       "L 367.803125 515.005364 \n",
       "L 411.660268 502.155619 \n",
       "L 455.517411 488.813204 \n",
       "L 499.374554 472.822849 \n",
       "L 543.231696 454.389794 \n",
       "L 587.088839 439.774734 \n",
       "L 630.945982 422.73753 \n",
       "L 674.803125 398.39278 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_102\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 635.128037 \n",
       "L 104.660268 595.449794 \n",
       "L 148.517411 580.957894 \n",
       "L 192.374554 567.266525 \n",
       "L 236.231696 559.897423 \n",
       "L 280.088839 548.505054 \n",
       "L 323.945982 542.018594 \n",
       "L 367.803125 537.338496 \n",
       "L 411.660268 528.409351 \n",
       "L 455.517411 522.128162 \n",
       "L 499.374554 519.254411 \n",
       "L 543.231696 513.034794 \n",
       "L 587.088839 509.586293 \n",
       "L 630.945982 502.894577 \n",
       "L 674.803125 497.598665 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_103\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 642.53821 \n",
       "L 104.660268 593.643432 \n",
       "L 148.517411 580.259984 \n",
       "L 192.374554 567.882338 \n",
       "L 236.231696 551.481441 \n",
       "L 280.088839 536.845857 \n",
       "L 323.945982 528.840417 \n",
       "L 367.803125 516.072753 \n",
       "L 411.660268 504.351969 \n",
       "L 455.517411 487.232637 \n",
       "L 499.374554 472.227559 \n",
       "L 543.231696 458.207789 \n",
       "L 587.088839 441.314253 \n",
       "L 630.945982 420.6438 \n",
       "L 674.803125 408.389314 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_104\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 646.684614 \n",
       "L 104.660268 601.423076 \n",
       "L 148.517411 581.224738 \n",
       "L 192.374554 569.380794 \n",
       "L 236.231696 560.841652 \n",
       "L 280.088839 552.364098 \n",
       "L 323.945982 544.707613 \n",
       "L 367.803125 540.130135 \n",
       "L 411.660268 533.048401 \n",
       "L 455.517411 529.702535 \n",
       "L 499.374554 526.582465 \n",
       "L 543.231696 521.840779 \n",
       "L 587.088839 516.770663 \n",
       "L 630.945982 513.58902 \n",
       "L 674.803125 509.114178 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_105\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 620.80036 \n",
       "L 104.660268 583.72901 \n",
       "L 148.517411 563.017493 \n",
       "L 192.374554 554.190969 \n",
       "L 236.231696 537.93377 \n",
       "L 280.088839 531.159942 \n",
       "L 323.945982 524.940326 \n",
       "L 367.803125 513.424797 \n",
       "L 411.660268 496.223369 \n",
       "L 455.517411 478.11876 \n",
       "L 499.374554 466.19269 \n",
       "L 543.231696 444.701182 \n",
       "L 587.088839 421.957493 \n",
       "L 630.945982 408.697205 \n",
       "L 674.803125 383.654545 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_106\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 659.411215 \n",
       "L 104.660268 625.583094 \n",
       "L 148.517411 592.76079 \n",
       "L 192.374554 582.43581 \n",
       "L 236.231696 577.714664 \n",
       "L 280.088839 572.151909 \n",
       "L 323.945982 561.950089 \n",
       "L 367.803125 556.94156 \n",
       "L 411.660268 550.229305 \n",
       "L 455.517411 549.859826 \n",
       "L 499.374554 549.100343 \n",
       "L 543.231696 540.314882 \n",
       "L 587.088839 541.115428 \n",
       "L 630.945982 535.532134 \n",
       "L 674.803125 526.11035 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_107\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 625.891001 \n",
       "L 104.660268 584.324284 \n",
       "L 148.517411 571.987686 \n",
       "L 192.374554 556.223126 \n",
       "L 236.231696 548.854009 \n",
       "L 280.088839 529.661487 \n",
       "L 323.945982 518.659137 \n",
       "L 367.803125 508.970494 \n",
       "L 411.660268 495.258616 \n",
       "L 455.517411 482.244648 \n",
       "L 499.374554 464.612123 \n",
       "L 543.231696 444.167465 \n",
       "L 587.088839 427.684471 \n",
       "L 630.945982 406.398204 \n",
       "L 674.803125 393.958971 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_108\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 607.334786 \n",
       "L 104.660268 589.271225 \n",
       "L 148.517411 581.245262 \n",
       "L 192.374554 572.747183 \n",
       "L 236.231696 567.656543 \n",
       "L 280.088839 567.246 \n",
       "L 323.945982 559.712675 \n",
       "L 367.803125 561.45745 \n",
       "L 411.660268 562.0322 \n",
       "L 455.517411 566.773886 \n",
       "L 499.374554 566.260723 \n",
       "L 543.231696 570.283959 \n",
       "L 587.088839 575.066708 \n",
       "L 630.945982 572.58296 \n",
       "L 674.803125 580.177873 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_109\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 634.389079 \n",
       "L 104.660268 593.253429 \n",
       "L 148.517411 581.512105 \n",
       "L 192.374554 571.720843 \n",
       "L 236.231696 571.679779 \n",
       "L 280.088839 568.169706 \n",
       "L 323.945982 559.774263 \n",
       "L 367.803125 563.510132 \n",
       "L 411.660268 557.844741 \n",
       "L 455.517411 559.03529 \n",
       "L 499.374554 553.00042 \n",
       "L 543.231696 555.853647 \n",
       "L 587.088839 555.217309 \n",
       "L 630.945982 559.322672 \n",
       "L 674.803125 558.33738 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_110\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 639.048653 \n",
       "L 104.660268 595.716637 \n",
       "L 148.517411 587.813833 \n",
       "L 192.374554 586.356426 \n",
       "L 236.231696 567.184428 \n",
       "L 280.088839 565.152271 \n",
       "L 323.945982 561.436926 \n",
       "L 367.803125 564.556997 \n",
       "L 411.660268 564.413313 \n",
       "L 455.517411 565.234382 \n",
       "L 499.374554 567.287064 \n",
       "L 543.231696 568.990775 \n",
       "L 587.088839 577.817284 \n",
       "L 630.945982 573.814572 \n",
       "L 674.803125 577.324646 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_111\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 647.23884 \n",
       "L 104.660268 600.232528 \n",
       "L 148.517411 585.555881 \n",
       "L 192.374554 574.840913 \n",
       "L 236.231696 569.278158 \n",
       "L 280.088839 563.30486 \n",
       "L 323.945982 560.554269 \n",
       "L 367.803125 557.495786 \n",
       "L 411.660268 554.375716 \n",
       "L 455.517411 557.167355 \n",
       "L 499.374554 555.894695 \n",
       "L 543.231696 550.516687 \n",
       "L 587.088839 554.868354 \n",
       "L 630.945982 552.076715 \n",
       "L 674.803125 552.281986 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_112\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 620.184547 \n",
       "L 104.660268 587.834357 \n",
       "L 148.517411 577.509393 \n",
       "L 192.374554 566.650726 \n",
       "L 236.231696 568.313389 \n",
       "L 280.088839 561.867993 \n",
       "L 323.945982 558.111584 \n",
       "L 367.803125 568.416025 \n",
       "L 411.660268 562.771174 \n",
       "L 455.517411 570.448182 \n",
       "L 499.374554 569.688685 \n",
       "L 543.231696 570.058164 \n",
       "L 587.088839 580.896307 \n",
       "L 630.945982 575.25144 \n",
       "L 674.803125 581.902123 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_113\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 660.745455 \n",
       "L 104.660268 621.888273 \n",
       "L 148.517411 591.016 \n",
       "L 192.374554 584.816923 \n",
       "L 236.231696 580.034189 \n",
       "L 280.088839 579.007848 \n",
       "L 323.945982 572.972979 \n",
       "L 367.803125 568.806043 \n",
       "L 411.660268 567.861814 \n",
       "L 455.517411 569.811845 \n",
       "L 499.374554 561.970628 \n",
       "L 543.231696 558.686335 \n",
       "L 587.088839 556.592605 \n",
       "L 630.945982 560.30795 \n",
       "L 674.803125 558.871082 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_114\">\n",
       "    <path clip-path=\"url(#p28e2ef4948)\" d=\"M 60.803125 624.844136 \n",
       "L 104.660268 584.714287 \n",
       "L 148.517411 583.338991 \n",
       "L 192.374554 569.46289 \n",
       "L 236.231696 575.559347 \n",
       "L 280.088839 564.228566 \n",
       "L 323.945982 561.067447 \n",
       "L 367.803125 562.504315 \n",
       "L 411.660268 570.140276 \n",
       "L 455.517411 561.375354 \n",
       "L 499.374554 567.841275 \n",
       "L 543.231696 575.600395 \n",
       "L 587.088839 572.357165 \n",
       "L 630.945982 578.823101 \n",
       "L 674.803125 578.125191 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 30.103125 674.6 \n",
       "L 30.103125 369.8 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 705.503125 674.6 \n",
       "L 705.503125 369.8 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 30.103125 674.6 \n",
       "L 705.503125 674.6 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 30.103125 369.8 \n",
       "L 705.503125 369.8 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_46\">\n",
       "    <!-- Accuracy -->\n",
       "    <defs>\n",
       "     <path d=\"M 34.1875 63.1875 \n",
       "L 20.796875 26.90625 \n",
       "L 47.609375 26.90625 \n",
       "z\n",
       "M 28.609375 72.90625 \n",
       "L 39.796875 72.90625 \n",
       "L 67.578125 0 \n",
       "L 57.328125 0 \n",
       "L 50.6875 18.703125 \n",
       "L 17.828125 18.703125 \n",
       "L 11.1875 0 \n",
       "L 0.78125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-65\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(340.409375 363.8)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_2\">\n",
       "    <g id=\"patch_13\">\n",
       "     <path d=\"M 37.103125 583.29375 \n",
       "L 160.320313 583.29375 \n",
       "Q 162.320313 583.29375 162.320313 581.29375 \n",
       "L 162.320313 376.8 \n",
       "Q 162.320313 374.8 160.320313 374.8 \n",
       "L 37.103125 374.8 \n",
       "Q 35.103125 374.8 35.103125 376.8 \n",
       "L 35.103125 581.29375 \n",
       "Q 35.103125 583.29375 37.103125 583.29375 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_115\">\n",
       "     <path d=\"M 39.103125 382.898437 \n",
       "L 59.103125 382.898437 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_116\"/>\n",
       "    <g id=\"text_47\">\n",
       "     <!-- Base -->\n",
       "     <g transform=\"translate(67.103125 386.398437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use x=\"68.603516\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"129.882812\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"181.982422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_117\">\n",
       "     <path d=\"M 39.103125 397.576562 \n",
       "L 59.103125 397.576562 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_118\"/>\n",
       "    <g id=\"text_48\">\n",
       "     <!-- VarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 401.076562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"403.574219\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"473.398438\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"536.777344\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"598.300781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"653.28125\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_119\">\n",
       "     <path d=\"M 39.103125 412.254687 \n",
       "L 59.103125 412.254687 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_120\"/>\n",
       "    <g id=\"text_49\">\n",
       "     <!-- VarDrop -->\n",
       "     <g transform=\"translate(67.103125 415.754687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_121\">\n",
       "     <path d=\"M 39.103125 426.932812 \n",
       "L 59.103125 426.932812 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_122\"/>\n",
       "    <g id=\"text_50\">\n",
       "     <!-- FastVarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 430.432812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"604.556641\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"674.380859\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"737.759766\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"799.283203\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"854.263672\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_123\">\n",
       "     <path d=\"M 39.103125 441.610937 \n",
       "L 59.103125 441.610937 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_124\"/>\n",
       "    <g id=\"text_51\">\n",
       "     <!-- FastVarDrop -->\n",
       "     <g transform=\"translate(67.103125 445.110937)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_125\">\n",
       "     <path d=\"M 39.103125 456.289062 \n",
       "L 59.103125 456.289062 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_126\"/>\n",
       "    <g id=\"text_52\">\n",
       "     <!-- HandmadeCheck -->\n",
       "     <g transform=\"translate(67.103125 459.789062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"616.845703\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"680.224609\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"741.748047\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"796.728516\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_127\">\n",
       "     <path d=\"M 39.103125 470.967187 \n",
       "L 59.103125 470.967187 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_128\"/>\n",
       "    <g id=\"text_53\">\n",
       "     <!-- Handmade -->\n",
       "     <g transform=\"translate(67.103125 474.467187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_129\">\n",
       "     <path d=\"M 39.103125 485.645312 \n",
       "L 59.103125 485.645312 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_130\"/>\n",
       "    <g id=\"text_54\">\n",
       "     <!-- Base -->\n",
       "     <g transform=\"translate(67.103125 489.145312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use x=\"68.603516\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"129.882812\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"181.982422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_131\">\n",
       "     <path d=\"M 39.103125 500.323437 \n",
       "L 59.103125 500.323437 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_132\"/>\n",
       "    <g id=\"text_55\">\n",
       "     <!-- VarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 503.823437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"403.574219\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"473.398438\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"536.777344\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"598.300781\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"653.28125\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_133\">\n",
       "     <path d=\"M 39.103125 515.001562 \n",
       "L 59.103125 515.001562 \n",
       "\" style=\"fill:none;stroke:#00008b;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_134\"/>\n",
       "    <g id=\"text_56\">\n",
       "     <!-- VarDrop -->\n",
       "     <g transform=\"translate(67.103125 518.501562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"163.050781\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"240.052734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"278.916016\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"340.097656\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_135\">\n",
       "     <path d=\"M 39.103125 529.679687 \n",
       "L 59.103125 529.679687 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_136\"/>\n",
       "    <g id=\"text_57\">\n",
       "     <!-- FastVarDropCheck -->\n",
       "     <g transform=\"translate(67.103125 533.179687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"604.556641\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"674.380859\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"737.759766\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"799.283203\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"854.263672\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_137\">\n",
       "     <path d=\"M 39.103125 544.357812 \n",
       "L 59.103125 544.357812 \n",
       "\" style=\"fill:none;stroke:#ffa500;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_138\"/>\n",
       "    <g id=\"text_58\">\n",
       "     <!-- FastVarDrop -->\n",
       "     <g transform=\"translate(67.103125 547.857812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"261.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"322.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"364.033203\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"441.035156\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"479.898438\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"541.080078\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_139\">\n",
       "     <path d=\"M 39.103125 559.035937 \n",
       "L 59.103125 559.035937 \n",
       "\" style=\"fill:none;stroke:#a52a2a;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_140\"/>\n",
       "    <g id=\"text_59\">\n",
       "     <!-- HandmadeCheck -->\n",
       "     <g transform=\"translate(67.103125 562.535937)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"616.845703\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"680.224609\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"741.748047\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"796.728516\" xlink:href=\"#DejaVuSans-107\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_141\">\n",
       "     <path d=\"M 39.103125 573.714062 \n",
       "L 59.103125 573.714062 \n",
       "\" style=\"fill:none;stroke:#ee82ee;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_142\"/>\n",
       "    <g id=\"text_60\">\n",
       "     <!-- Handmade -->\n",
       "     <g transform=\"translate(67.103125 577.214062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p018823bbda\">\n",
       "   <rect height=\"304.8\" width=\"675.4\" x=\"30.103125\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p28e2ef4948\">\n",
       "   <rect height=\"304.8\" width=\"675.4\" x=\"30.103125\" y=\"369.8\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "axes[0].grid(True)\n",
    "axes[0].plot(np.arange(len(train_losses_pure)), [i.item() for i in train_losses_pure],\n",
    "             label='Base', linestyle='-', color='black')\n",
    "\n",
    "axes[0].plot(np.arange(len(train_losses_vd_drop)), [i.item() for i in train_losses_vd_drop],\n",
    "             label='VarDropCheck', linestyle='-', color='red')\n",
    "axes[0].plot(np.arange(len(train_losses_vd_no_drop)), [i.item() for i in train_losses_vd_no_drop],\n",
    "             label='VarDrop', linestyle='-', color='darkblue')\n",
    "\n",
    "axes[0].plot(np.arange(len(train_losses_vd2_drop)), [i.item() for i in train_losses_vd2_drop],\n",
    "             label='FastVarDropCheck', linestyle='-', color='green')\n",
    "axes[0].plot(np.arange(len(train_losses_vd2_no_drop)), [i.item() for i in train_losses_vd2_no_drop],\n",
    "             label='FastVarDrop', linestyle='-', color='orange')\n",
    "\n",
    "axes[0].plot(np.arange(len(train_losses_drop3)), [i.item() for i in train_losses_drop3],\n",
    "             label='HandmadeCheck', linestyle='-', color='brown')\n",
    "axes[0].plot(np.arange(len(train_losses_no_drop3)), [i.item() for i in train_losses_no_drop3],\n",
    "             label='Handmade', linestyle='-', color='violet')\n",
    "\n",
    "axes[0].plot(np.arange(len(test_losses_pure)), [i.item() for i in test_losses_pure],\n",
    "             label='Base', linestyle='--', color='black')\n",
    "\n",
    "axes[0].plot(np.arange(len(test_losses_vd_drop)), [i.item() for i in test_losses_vd_drop],\n",
    "             label='VarDropCheck', linestyle='--', color='red')\n",
    "axes[0].plot(np.arange(len(test_losses_vd_no_drop)), [i.item() for i in test_losses_vd_no_drop],\n",
    "             label='VarDrop', linestyle='--', color='darkblue')\n",
    "\n",
    "axes[0].plot(np.arange(len(test_losses_vd2_drop)), [i.item() for i in test_losses_vd2_drop],\n",
    "             label='FastVarDropCheck', linestyle='--', color='green')\n",
    "axes[0].plot(np.arange(len(test_losses_vd2_no_drop)), [i.item() for i in test_losses_vd2_no_drop],\n",
    "             label='FastVarDrop', linestyle='--', color='orange')\n",
    "\n",
    "axes[0].plot(np.arange(len(test_losses_drop3)), [i.item() for i in test_losses_drop3],\n",
    "             label='HandmadeCheck', linestyle='--', color='brown')\n",
    "axes[0].plot(np.arange(len(test_losses_no_drop3)), [i.item() for i in test_losses_no_drop3],\n",
    "             label='Handmade', linestyle='--', color='violet')\n",
    "\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[1].plot(np.arange(len(train_accuracies_pure)), [i.item() for i in train_accuracies_pure],\n",
    "             label='Base', linestyle='-', color='black')\n",
    "\n",
    "axes[1].plot(np.arange(len(train_accuracies_vd_drop)), [i.item() for i in train_accuracies_vd_drop],\n",
    "             label='VarDropCheck', linestyle='-', color='red')\n",
    "axes[1].plot(np.arange(len(train_accuracies_vd_no_drop)), [i.item() for i in train_accuracies_vd_no_drop],\n",
    "             label='VarDrop', linestyle='-', color='darkblue')\n",
    "\n",
    "axes[1].plot(np.arange(len(train_accuracies_vd2_drop)), [i.item() for i in train_accuracies_vd2_drop],\n",
    "             label='FastVarDropCheck', linestyle='-', color='green')\n",
    "axes[1].plot(np.arange(len(train_accuracies_vd2_no_drop)), [i.item() for i in train_accuracies_vd2_no_drop],\n",
    "             label='FastVarDrop', linestyle='-', color='orange')\n",
    "\n",
    "axes[1].plot(np.arange(len(train_accuracies_drop3)), [i.item() for i in train_accuracies_drop3],\n",
    "             label='HandmadeCheck', linestyle='-', color='brown')\n",
    "axes[1].plot(np.arange(len(train_accuracies_no_drop3)), [i.item() for i in train_accuracies_no_drop3],\n",
    "             label='Handmade', linestyle='-', color='violet')\n",
    "\n",
    "axes[1].plot(np.arange(len(test_accuracies_pure)), [i.item() for i in test_accuracies_pure],\n",
    "             label='Base', linestyle='--', color='black')\n",
    "\n",
    "axes[1].plot(np.arange(len(test_accuracies_vd_drop)), [i.item() for i in test_accuracies_vd_drop],\n",
    "             label='VarDropCheck', linestyle='--', color='red')\n",
    "axes[1].plot(np.arange(len(test_accuracies_vd_no_drop)), [i.item() for i in test_accuracies_vd_no_drop],\n",
    "             label='VarDrop', linestyle='--', color='darkblue')\n",
    "\n",
    "axes[1].plot(np.arange(len(test_accuracies_vd2_drop)), [i.item() for i in test_accuracies_vd2_drop],\n",
    "             label='FastVarDropCheck', linestyle='--', color='green')\n",
    "axes[1].plot(np.arange(len(test_accuracies_vd2_no_drop)), [i.item() for i in test_accuracies_vd2_no_drop],\n",
    "             label='FastVarDrop', linestyle='--', color='orange')\n",
    "\n",
    "axes[1].plot(np.arange(len(test_accuracies_drop3)), [i.item() for i in test_accuracies_drop3],\n",
    "             label='HandmadeCheck', linestyle='--', color='brown')\n",
    "axes[1].plot(np.arange(len(test_accuracies_no_drop3)), [i.item() for i in test_accuracies_no_drop3],\n",
    "             label='Handmade', linestyle='--', color='violet')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_title('Accuracy')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doV1d9tmt4y2"
   },
   "source": [
    "Сделайте итоговые выводы о качестве работы моделей с разными реализациями DropOut:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLanA2Aet4y2"
   },
   "source": [
    "**Ответ:** модели FastVarDropCheck и HandmadeCheck показывают схожее качество на обучении и на тесте, что свидетельствует об устойчивости к проблеме переобучения. Также по графикам видно, что все модели с включенным дропаутом более усточивы к переобучению, чем их аналоги с выключенным дропаутом.\n",
    "\n",
    "P.S. На графиках пунктир означает тест, префикс \"Check\" - модель с парметром dropout=0.25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUmPHYpGt4y3"
   },
   "source": [
    "## Бонус. Zoneout (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCzCJiOtt4y3"
   },
   "source": [
    "Это еще одна модификация идеи дропаута применительно к рекуррентным нейросетям. В Zoneout на каждом временном шаге с вероятностью p компонента скрытого состояния обновляется, а с вероятностью 1-p берется с предыдущего шага. \n",
    "В Виде формул (m^t_h - бинарная маска):\n",
    " \n",
    "(сначала обычный рекуррентный переход, например LSTM)\n",
    "$$\n",
    "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
    "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
    "$$\n",
    "$$\n",
    "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
    "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
    "$$\n",
    "$$\n",
    "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
    "h_t =  o \\odot tanh(c_t) \\nonumber\n",
    "$$\n",
    "Затем Zoneout:\n",
    "$$\n",
    "h_t = h_t * m_h^t + h_{t-1}*(1-m_h^t)\n",
    "$$\n",
    "В этом методе маска уже должна быть разная во все моменты времени (иначе метод упрощается до дропаута Гала и Гарамани). На входы $x_t$ вновь можно накладывать маску до начала работы рекуррентного слоя.  \n",
    "\n",
    "Если у вас осталось время, вы можете реализовать этот метод. Выберите основу из трех рассмотренных случаев самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eyq5QOEPa_j"
   },
   "outputs": [],
   "source": [
    "class Zoneout(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n",
    "        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        \n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        \"\"\"\n",
    "        Initialization as in Pytorch. \n",
    "        Do not forget to call this method!\n",
    "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n",
    "        \"\"\"\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use functions init_h0_c0 and gen_dropout_masks defined above\n",
    "        # YOUR CODE HERE\n",
    "        h0, c0 = init_h0_c0(x.size(1), self.hidden_size, x)\n",
    "        m_x, h_x = gen_dropout_mask(self.input_size, self.hidden_size,\n",
    "                                    self.training, self.dropout, x)   \n",
    "        # Implement recurrent logic to mimic torch.nn.LSTM\n",
    "        # Do not forget to apply dropout mask\n",
    "        # YOUR CODE HERE\n",
    "        out = []\n",
    "        h_t, c_t = h0, c0\n",
    "        for t in range(x.size(0)):\n",
    "            iofg = self.hidden_weights(h_t)+self.input_weights(x[t]*m_x)\n",
    "            i = torch.sigmoid(iofg[:, :self.hidden_size])\n",
    "            o = torch.sigmoid(iofg[:,self.hidden_size:2*self.hidden_size])\n",
    "            f = torch.sigmoid(iofg[:,2*self.hidden_size:3*self.hidden_size])\n",
    "            g = torch.tanh(iofg[..., 3*self.hidden_size:])\n",
    "            c_t = f*c_t + i*g\n",
    "            h_t = o * torch.tanh(c_t)\n",
    "            _, h_x = gen_dropout_mask(self.input_size, self.hidden_size,\n",
    "                                    self.training, self.dropout, x) \n",
    "            h_t = h_t * h_x + out[-1] * (1-h_x)\n",
    "            out.append(h_t)\n",
    "        return torch.stack(out), (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:05:00.702763Z",
     "start_time": "2021-03-31T16:05:00.674835Z"
    },
    "id": "6TJ7w2b4t4y3"
   },
   "source": [
    "# Часть 2. Language Modeling с помощью LSTM. (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGzIWsRBt4y4"
   },
   "source": [
    "Во второй части мы попробуем обучить модель для генерации отзывов по их началу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyNf-lN0t4y6"
   },
   "source": [
    "Концептуально модель будет выглядеть следующим образом:\n",
    "    \n",
    "![image info](https://blog.feedly.com/wp-content/uploads/2019/03/Screen-Shot-2019-03-06-at-12.08.35-PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn6y0CvNt4y7"
   },
   "source": [
    "В процессе обучения будем тренировать сеть предсказывать вероятность следующего символа при условии всех предыдущих. Эту вероятность можно моделировать с помощью скрытого состояния $h^{(t)}$ пропуская его через линейный слой с выходной размерностью равной размерности словаря:\n",
    "$$\n",
    "p(x^{t}|x^{t-1}, ..., x^{1}) = SoftMax(Linear(h^{(t)}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgKVfYBnt4y9"
   },
   "source": [
    "Обратите внимание, что для вычисления $p(x^{t}|x^{t-1}, ..., x^{1})$ для всех моментов времени достаточно сделать один проход по RNN, а затем применить линейное преобразование ко всем скрытым состояниям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:37:56.100520Z",
     "start_time": "2021-04-02T00:37:56.072747Z"
    },
    "id": "mpDE2I0Gt4y-"
   },
   "source": [
    "В качестве функции потерь необходимо использовать `CrossEntropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFN_6z1Nt4y-"
   },
   "source": [
    "Рассмотрим другой важный момент. Для того, чтобы решить данную задачу, модель должна уметь определять момент начала генерации предложения и оповещать о завершении генерации -- конце предложения. Для этого добавим в словарь вспомогательные токены `<sos>`, `<eos>`. Добавив `<sos>` в начало каждого предложения и `<eos>` в конец.\n",
    "\n",
    "Модель сможет начинать генерацию как только ей будет передан токен `<sos>` и заканчивать генерацию, как только на очередном месте самым вероятным токеном оказывается `<eos>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL87QYmwt4y_"
   },
   "source": [
    "Для решения этой задачи мы воспользуемся уже реализованной LSTM с дропаутом `FastRNNLayer` и классом `RNNClassifier`, то есть архитектура сети принципиально не поменяется. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrjmlmp8t4y_"
   },
   "source": [
    "## Реализация модели и цикла обучения (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfrPYfv9t4y_"
   },
   "source": [
    "**Не используйте циклы в `RNNLM`, `LMCrossEntropyLoss`, `LMAccuracy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:07:02.815198Z",
     "start_time": "2021-04-02T02:07:02.787445Z"
    },
    "id": "HwtTBIgHt4zA"
   },
   "outputs": [],
   "source": [
    "class RNNLM(RNNClassifier):\n",
    "    def __init__(\n",
    "        self, embedding_dim, hidden_dim, vocab, dropout=0.5, layers_dropout=0.5, num_layers=1\n",
    "    ):\n",
    "        super().__init__(\n",
    "            embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=len(vocab), vocab=vocab,\n",
    "            rec_layer=FastRNNLayer, dropout=dropout, layers_dropout=layers_dropout, num_layers=num_layers\n",
    "        )\n",
    "    \n",
    "    def forward(self, tokens, tokens_lens):\n",
    "        \"\"\"\n",
    "        :param torch.tensor(dtype=torch.long) tokens: Batch of texts represented with tokens. Shape: [T, B]\n",
    "        :param torch.tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch. Shape: [B]\n",
    "        :return torch.tensor: Distribution of next token for each time step. Shape: [T, B, V], V -- size of vocabulary\n",
    "        \"\"\"\n",
    "        # Make embeddings for all tokens\n",
    "        # YOUR CODE HERE\n",
    "        layer1 = self.word_embeddings(tokens)\n",
    "        \n",
    "        # Forward pass embeddings through network\n",
    "        # YOUR CODE HERE\n",
    "        out_h, hidden = self.rnn(layer1)\n",
    "        # Take all hidden states from the last layer of LSTM for each step and perform linear transformation\n",
    "        # YOUR CODE HERE\n",
    "        return self.output(out_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIZR5crOt4zA"
   },
   "source": [
    "Реализуем функцию потерь для данной задачи. \n",
    "\n",
    "Моменты на которые нужно обратить внимание:\n",
    "1. Распределение вероятности следующего токена для последнего токена в последовательности не участвует в подсчёте функции потерь.\n",
    "2. Необходимо учитывать, что в одном батче могут быть тексты разной длины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkquWyJ7t4zB"
   },
   "source": [
    "Для решения второй проблемы можно воспользоваться функцией `torch.nn.utils.rnn.pack_padded_sequence`. \n",
    "\n",
    "Принимая на вход батч тензоров и длину каждого тензора без учёта паддинга эта функция позволяет получить все элементы в тензорах, которые не относятся к паддингу в виде плоского массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:54:40.004897Z",
     "start_time": "2021-04-02T00:54:39.977287Z"
    },
    "id": "PtC-9a-it4zB"
   },
   "outputs": [],
   "source": [
    "padded_tensors = torch.tensor([\n",
    "    [[1, 11, 111], [2, 22, 222], [3, 33, 333]],\n",
    "    [[4, 44, 444], [5, 55, 555], [6, 66, 666]],\n",
    "    [[7, 77, 777], [0, 0, 0], [8, 88, 888]],\n",
    "    [[9, 99, 999], [0, 0, 0], [0, 0, 0]]\n",
    "])\n",
    "tensors_lens = torch.tensor([4, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFlLJUTIuiWk",
    "outputId": "456c67a3-0ca2-4cb0-e7e5-0d51a1819237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWArQCu0t4zC"
   },
   "source": [
    "Обратите внимание, что `torch.nn.utils.rnn.pack_padded_sequence` автоматически переупорядочивает тензоры в батче по убыванию их длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:54:24.517023Z",
     "start_time": "2021-04-02T00:54:24.490588Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzTRGEGHt4zC",
    "outputId": "54d39973-daa4-46e3-890c-743d74d05c16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[  1,  11, 111],\n",
       "        [  3,  33, 333],\n",
       "        [  2,  22, 222],\n",
       "        [  4,  44, 444],\n",
       "        [  6,  66, 666],\n",
       "        [  5,  55, 555],\n",
       "        [  7,  77, 777],\n",
       "        [  8,  88, 888],\n",
       "        [  9,  99, 999]]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pack_padded_sequence(padded_tensors, tensors_lens, batch_first=False, enforce_sorted=False)#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:07:06.289671Z",
     "start_time": "2021-04-02T02:07:06.262883Z"
    },
    "id": "ETOQf9mKt4zD"
   },
   "outputs": [],
   "source": [
    "class LMCrossEntropyLoss(torch.nn.CrossEntropyLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def forward(self, outputs, tokens, tokens_lens):\n",
    "        \"\"\"\n",
    "        :param torch.tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
    "        :param torch.tensor tokens: Batch of tokens. Shape: [T, B]\n",
    "        :param torch.tensor tokens_lens: Length of each sequence in batch\n",
    "        :return torch.tensor: CrossEntropyLoss between corresponding logits and tokens\n",
    "        \"\"\"\n",
    "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
    "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
    "        # YOUR CODE HERE\n",
    "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs, tokens_lens.cpu()-1, \n",
    "                                                                 batch_first=False, enforce_sorted=False).data\n",
    "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens[1:], tokens_lens.cpu()-1, \n",
    "                                                                batch_first=False, enforce_sorted=False).data\n",
    "        \n",
    "        # Use super().forward(..., ...) to compute CrossEntropyLoss\n",
    "        # YOUR CODE HERE\n",
    "        return super().forward(packed_outputs, packed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvBJI5KUt4zD"
   },
   "source": [
    "Для оценки качества нам также необходимо вычислять долю правильно предсказанных токенов. Реализуйте класс для вычисления точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:07:07.335981Z",
     "start_time": "2021-04-02T02:07:07.309586Z"
    },
    "id": "8RnT3LHOt4zD"
   },
   "outputs": [],
   "source": [
    "class LMAccuracy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, outputs, tokens, tokens_lens):\n",
    "        \"\"\"\n",
    "        :param torch.tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
    "        :param torch.tensor tokens: Batch of tokens. Shape: [T, B]\n",
    "        :param torch.tensor tokens_lens: Length of each sequence in batch\n",
    "        :return torch.tensor: Accuracy for given logits and tokens\n",
    "        \"\"\"\n",
    "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
    "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
    "        # YOUR CODE HERE\n",
    "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs, tokens_lens.cpu()-1, \n",
    "                                                                 batch_first=False, enforce_sorted=False).data\n",
    "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens[1:, :], tokens_lens.cpu()-1,\n",
    "                                                                batch_first=False, enforce_sorted=False).data\n",
    "\n",
    "        return torch.sum(packed_outputs.argmax(1) == packed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMVOKB38t4zE"
   },
   "source": [
    "Модифицируйте функции `train_epoch`, `evaluate`, `train` для обучения LM.\n",
    "\n",
    "**При вычислении точности, обратите внимание на то, что мы не предсказываем первый токен в каждой последовательности и токены, относящиеся к паддингу.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:07:31.492984Z",
     "start_time": "2021-04-02T02:07:31.459655Z"
    },
    "id": "_CtEDkrWt4zE"
   },
   "outputs": [],
   "source": [
    "def train_epoch_lm(dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        # 1. Take data from batch\n",
    "        # 2. Perform forward pass\n",
    "        # 3. Evaluate loss\n",
    "        # 4. Make optimizer step\n",
    "        # YOUR CODE HERE\n",
    "        optimizer.zero_grad()\n",
    "        tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
    "        predict = model(tokens, tokens_lens)\n",
    "        loss = loss_fn(predict, tokens, tokens_lens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "def evaluate_lm(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_tokens = 0\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    accuracy_fn = LMAccuracy()\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            # 1. Take data from batch\n",
    "            # 2. Perform forward pass\n",
    "            # 3. Evaluate loss\n",
    "            # 4. Evaluate accuracy\n",
    "            # YOUR CODE HERE\n",
    "            tokens, tokens_lens = data['tokens'].to(device), data['tokens_lens'].to(device)\n",
    "            predict = model(tokens, tokens_lens).to(device)\n",
    "            \n",
    "            total_loss += loss_fn(predict, tokens, tokens_lens)\n",
    "            total_accuracy += accuracy_fn(predict, tokens, tokens_lens)\n",
    "            total_tokens += torch.sum(tokens_lens - 1)          \n",
    "    return total_loss / total_tokens, total_accuracy / total_tokens\n",
    "\n",
    "def train_lm(\n",
    "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
    "):\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch_lm(train_loader, model, loss_fn, optimizer, device)\n",
    "        \n",
    "        train_loss, train_acc = evaluate_lm(train_loader, model, loss_fn, device)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        test_loss, test_acc = evaluate_lm(test_loader, model, loss_fn, device)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(\n",
    "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
    "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
    "            )\n",
    "        )\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4autLTdht4zF"
   },
   "source": [
    "Теперь у нас всё готово для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T01:06:12.736180Z",
     "start_time": "2021-04-02T01:06:12.708814Z"
    },
    "id": "iQS3Wakdt4zF"
   },
   "source": [
    "Создадим словарь с `<sos>`, `<eos>` токенами.\n",
    "\n",
    "Обратите внимание, что в отличие от классификации текстов нам необходимо значительно увеличить размер словаря, чтобы доля `<unk>` токенов была не велика.\n",
    "\n",
    "Так же, так как задача генерации значительно сложнее задачи классификации текстов будем обучать модель только на префиксах рецензий длины $20$. Это позволяет значительно ускорить обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "-KO2fhRi5ohP"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "for i, l in counter.items():\n",
    "    c[i] = l\n",
    "\n",
    "new_counter = {}\n",
    "for i, l in c.most_common(30000):\n",
    "    new_counter[i] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:06:20.093645Z",
     "start_time": "2021-04-02T00:06:19.926668Z"
    },
    "id": "SBDq0tYjt4zG"
   },
   "outputs": [],
   "source": [
    "specials = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "for special in specials:\n",
    "    counter[special] = 0\n",
    "lm_vocab = torchtext.vocab.vocab(new_counter, specials=specials, special_first=True)\n",
    "lm_vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T00:06:58.566893Z",
     "start_time": "2021-04-02T00:06:21.430692Z"
    },
    "id": "pAFnKJRgt4zG"
   },
   "outputs": [],
   "source": [
    "# max_len=18 с учетом еще 2х специальных токенов\n",
    "\n",
    "lm_test_dataset = LargeMovieReviewDataset(test_data_path, lm_vocab, max_len=18, pad_sos=True, pad_eos=True)\n",
    "lm_train_dataset = LargeMovieReviewDataset(train_data_path, lm_vocab, max_len=18, pad_sos=True, pad_eos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yaVeAfDt4zG"
   },
   "source": [
    "Создадим даталоадеры для тестовой и обучающей выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T12:29:16.213723Z",
     "start_time": "2021-04-02T12:29:16.186954Z"
    },
    "id": "E68TsW7Ct4zH"
   },
   "outputs": [],
   "source": [
    "lm_test_dataloader = DataLoader(\n",
    "    lm_test_dataset, batch_size=96, shuffle=False, num_workers=0, \n",
    "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
    ")\n",
    "lm_train_dataloader = DataLoader(\n",
    "    lm_train_dataset, batch_size=96, shuffle=True, num_workers=0, \n",
    "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xImJ9FlBt4zH"
   },
   "source": [
    "Убедитесь, что все предложения имеют в начале `<sos>` токен, а в конце -- `<eos>` токен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T12:29:17.218115Z",
     "start_time": "2021-04-02T12:29:16.922801Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG_lBHbGt4zH",
    "outputId": "a7b4cba3-a50d-4933-9277-d261e06c5b3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
       "         [  882,   874,  1128,  ...,  4237,    58,  1067],\n",
       "         [  687,   166,   148,  ...,   298,   736,     8],\n",
       "         ...,\n",
       "         [ 1774, 10247,   610,  ...,    49, 24392,  1054],\n",
       "         [  335,   117,    21,  ...,  1355,     1,   245],\n",
       "         [    3,     3,     3,  ...,     3,     3,     3]]),\n",
       " tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(lm_train_dataloader))\n",
    "batch['tokens'], batch['tokens_lens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEPPuU1H8N8I",
    "outputId": "eaf63104-1737-4d80-d704-c4060f981233"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_vocab.lookup_indices(['<sos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7exPdHRt4zH"
   },
   "source": [
    "Создадим модель, функцию потерь и оптимизатор: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T14:15:32.916424Z",
     "start_time": "2021-04-02T14:15:32.525452Z"
    },
    "id": "Ub93cbtot4zI"
   },
   "outputs": [],
   "source": [
    "lm_model = RNNLM(\n",
    "    embedding_dim=512, hidden_dim=512, vocab=lm_vocab, dropout=0.6, layers_dropout=0.6, num_layers=2\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T14:15:33.332806Z",
     "start_time": "2021-04-02T14:15:33.307749Z"
    },
    "id": "5JE-R3Xit4zI"
   },
   "outputs": [],
   "source": [
    "lm_loss_fn = LMCrossEntropyLoss(reduction='sum')\n",
    "lm_optimizer = torch.optim.Adam(lm_model.parameters(), lr=0.005, weight_decay=1.2e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t313EayNt4zJ"
   },
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T14:20:33.447251Z",
     "start_time": "2021-04-02T14:15:33.797444Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SgPMaFdt4zJ",
    "outputId": "585d4aee-d4e3-4219-9b27-87bbc813a671",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10. Loss (Train/Test): 7.449/7.611. Accuracy (Train/Test): 0.092/0.092\n",
      "Epoch: 2/10. Loss (Train/Test): 7.258/7.511. Accuracy (Train/Test): 0.098/0.098\n",
      "Epoch: 3/10. Loss (Train/Test): 7.092/7.445. Accuracy (Train/Test): 0.102/0.102\n",
      "Epoch: 4/10. Loss (Train/Test): 6.952/7.412. Accuracy (Train/Test): 0.107/0.106\n",
      "Epoch: 5/10. Loss (Train/Test): 6.827/7.396. Accuracy (Train/Test): 0.108/0.107\n",
      "Epoch: 6/10. Loss (Train/Test): 6.729/7.408. Accuracy (Train/Test): 0.110/0.109\n",
      "Epoch: 7/10. Loss (Train/Test): 6.633/7.437. Accuracy (Train/Test): 0.111/0.109\n",
      "Epoch: 8/10. Loss (Train/Test): 6.484/7.429. Accuracy (Train/Test): 0.113/0.110\n",
      "Epoch: 9/10. Loss (Train/Test): 6.406/7.484. Accuracy (Train/Test): 0.114/0.111\n",
      "Epoch: 10/10. Loss (Train/Test): 6.290/7.524. Accuracy (Train/Test): 0.114/0.110\n"
     ]
    }
   ],
   "source": [
    "lm_train_losses, lm_train_accuracies, lm_test_losses, lm_test_accuracies = train_lm(\n",
    "    lm_train_dataloader, lm_test_dataloader, lm_model, lm_loss_fn, lm_optimizer, device, 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHjcjMn3t4zK"
   },
   "source": [
    "## Реализация декодера. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO-JLGmRt4zL"
   },
   "source": [
    "Теперь, реализуем последнюю деталь -- декодирование с использованием обученной модели.\n",
    "Есть несколько вариантов. Рассмотрим два самых простых:\n",
    "1. **Жадное декодирование.** На каждом шаге мы выбираем токен с максимальной вероятностью и используем его для обновления скрытого состояния RNN.\n",
    "2. **Top-k sampling.** На очередном шаге рассматриваются $k$ токенов с самыми большими вероятностями. Остальные токены игнорируются. Из выбранных токенов семплируется следующий токен пропорционально их вероятностям.\n",
    "\n",
    "Прочитать подробнее про разные варианты декодирования можно по ссылкам:\n",
    "1. [От huggingface](https://huggingface.co/blog/how-to-generate)\n",
    "2. [На towardsdatascience](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4kpIKSyt4zL"
   },
   "source": [
    "Существенным в процессе декодирования является критерий останова. Как только очередной самый вероятный символ оказался `<eos>`, то данная последовательность считается сгенерированной. Однако, может так оказаться, что `<eos>` никогда не будет выбран, тогда необходимо прекратить генерацию, как только длина последовательности перейдёт порог `max_generated_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "Xojr_1yRGCu0"
   },
   "outputs": [],
   "source": [
    "def decode(model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None):\n",
    "    \"\"\"\n",
    "    :param RNNLM model: Model\n",
    "    :param torch.tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
    "    :param torch.tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
    "    :return Tuple[torch.tensor, torch.tensor]. Newly predicted tokens and length of generated part. Shape [T*, B], [B]\n",
    "    \"\"\"\n",
    "    # Get embedding for start_tokens\n",
    "    # YOUR CODE HERE\n",
    "    embedding = model.word_embeddings(start_tokens)\n",
    "\n",
    "    # Pass embedding through rnn and collect hidden states and cell states for each time moment\n",
    "    all_h, all_c = [], []\n",
    "    h = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
    "    c = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
    "    for time_step in range(start_tokens.shape[0]):\n",
    "        output, (h, c) = model.rnn(torch.unsqueeze(embedding[time_step], dim=0), (h, c))\n",
    "        all_h.append(h)\n",
    "        all_c.append(c)\n",
    "\n",
    "    all_h = torch.stack(all_h, dim=1)\n",
    "    all_c = torch.stack(all_c, dim=1)\n",
    "    # Take final hidden state and cell state for each start sequence in batch\n",
    "    # We will use them as h_0, c_0 for generation new tokens\n",
    "    h = all_h[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
    "    c = all_c[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
    "\n",
    "    # List of predicted tokens for each time step\n",
    "    predicted_tokens = []\n",
    "    # Length of generated part for each object in the batch\n",
    "    decoded_lens = torch.zeros_like(start_tokens_lens, dtype=torch.long)\n",
    "    # Boolean mask where we store if the sequence has already generated\n",
    "    # i.e. `<eos>` was selected on any step\n",
    "    is_finished_decoding = torch.zeros_like(start_tokens_lens, dtype=torch.bool)\n",
    "\n",
    "    # Stop when all sequences in the batch are finished\n",
    "    while not torch.all(is_finished_decoding) and torch.max(decoded_lens) < max_generated_len:\n",
    "        # Evaluate next token distribution using hidden state h.\n",
    "        # Note. Over first dimension h has hidden states for each layer of LSTM.\n",
    "        #     We must use hidden state from the last layer\n",
    "        # YOUR CODE HERE\n",
    "        logits = model.output(h[-1])\n",
    "\n",
    "        if top_k is not None:\n",
    "            # Top-k sampling. Use only top-k most probable logits to sample next token\n",
    "            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "            # Mask non top-k logits\n",
    "            logits[indices_to_remove] = -1e10\n",
    "            # Sample next_token. \n",
    "            # YOUR CODE HERE\n",
    "            next_token = torch.multinomial(torch.sigmoid(logits), 1).reshape(-1)\n",
    "        else:\n",
    "            # Select most probable token\n",
    "            # YOUR CODE HERE\n",
    "            next_token = torch.argmax(logits, dim=1).reshape(-1)\n",
    "\n",
    "        predicted_tokens.append(next_token)\n",
    "\n",
    "        decoded_lens += (~is_finished_decoding)\n",
    "        is_finished_decoding |= (next_token == torch.tensor(model.vocab.lookup_indices(['<eos>'])[0]))\n",
    "\n",
    "        # Evaluate embedding for next token\n",
    "        embedding += model.word_embeddings(next_token)\n",
    "\n",
    "        # Update hidden and cell states\n",
    "        output, (h, c) = model.rnn(embedding, (h, c))\n",
    "\n",
    "    return torch.stack(predicted_tokens), decoded_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T01:38:06.232189Z",
     "start_time": "2021-04-02T01:38:06.205413Z"
    },
    "id": "cAYC3b7Vt4zM"
   },
   "source": [
    "Попробуем сгенерировать продолжения для нескольких префиксов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T14:28:22.568613Z",
     "start_time": "2021-04-02T14:28:22.545810Z"
    },
    "id": "rdonELULt4zM"
   },
   "outputs": [],
   "source": [
    "start_tokens = torch.tensor([\n",
    "    lm_model.vocab.lookup_indices(['<sos>', '<pad>', '<pad>', '<pad>']),\n",
    "    lm_model.vocab.lookup_indices(['<sos>', 'my', 'favorite', 'movie']),\n",
    "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'best', 'movie']),\n",
    "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'worst', 'movie']),\n",
    "]).T\n",
    "\n",
    "start_tokens_lens = torch.tensor([1, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T14:28:28.222137Z",
     "start_time": "2021-04-02T14:28:27.930196Z"
    },
    "id": "cPG2m0sJt4zN"
   },
   "outputs": [],
   "source": [
    "lm_model = lm_model.cpu()\n",
    "lm_model.eval()\n",
    "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXHmoeTLwd3s",
    "outputId": "9f8574ed-818b-47d4-a422-49bfd6fe94c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> first time episode time thought thought im watching <unk> watching movie film going saw <unk> watching film im im hooked\n",
      "<sos> <unk> favorite movie seen ive never watched seen heard watched movie watched dvd dvd <eos>\n",
      "<sos> <unk> best movie ive seen seen ever heard heard seen movie saw <unk> <unk> watched dvd movie movie <eos>\n",
      "<sos> <unk> worst movie ever <unk> seen ive made watched <unk> seen seen one movie ive <unk> watched ever watched ever watched <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "for text_idx in range(start_tokens.shape[1]):\n",
    "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
    "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
    "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7JB9DjYt4zP"
   },
   "source": [
    "Попробуйте выполнить семплирование для разных $k$. Сравните результаты top-k семплирования с жадным декодированием. Опишите ваши наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T17:06:36.404126Z",
     "start_time": "2021-04-02T17:06:36.399654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwTXDTept4zP",
    "outputId": "4a2218b5-d73f-4888-cb05-3ae83eabc05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> movie bad bad bad bad bad bad bad bad bad bad bad bad <eos>\n",
      "<sos> <unk> favorite movie ever seen seen <unk> <unk> <unk> <eos>\n",
      "<sos> <unk> best movie ever seen seen seen movie <unk> <unk> <eos>\n",
      "<sos> <unk> worst movie ever seen seen seen movie <unk> <eos>\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "lm_model = lm_model.cpu()\n",
    "lm_model.eval()\n",
    "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None)\n",
    "\n",
    "for text_idx in range(start_tokens.shape[1]):\n",
    "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
    "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
    "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHMR0f4ZJ3cA",
    "outputId": "866c7bc3-da3d-45c9-c124-284b351a1bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> watched tv first dvd movie movie tv years years ago <unk> ago <eos>\n",
      "<sos> <unk> favorite movie made like movie like <unk> <unk> <unk> would film <eos>\n",
      "<sos> <unk> best movie year one night worst bin <unk> night school school night remember ago saw friday friday watched <eos>\n",
      "<sos> <unk> worst movie seen ive watched ive watched ever heard watching seen watched thinking years seen watched yesterday years many dvd last dvd\n"
     ]
    }
   ],
   "source": [
    "lm_model = lm_model.cpu()\n",
    "lm_model.eval()\n",
    "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=10)\n",
    "\n",
    "for text_idx in range(start_tokens.shape[1]):\n",
    "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
    "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
    "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQBbkpCsJ7-x",
    "outputId": "7d8be729-3ef4-40a1-895d-a437c67aaa37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> seen bad <unk> movie im good sure first film film going started even im even even one embarrassed going pretty\n",
      "<sos> <unk> favorite movie first im enjoyed really liked surprised like good one expecting would sure liked film bad <eos>\n",
      "<sos> <unk> best movie since really <unk> made ive really good movie glad bad liked <unk> bad going <eos>\n",
      "<sos> <unk> worst movie <unk> starring <unk> ive plot made would ever put put make like ever wasted <unk> say <unk> like bad see\n"
     ]
    }
   ],
   "source": [
    "lm_model = lm_model.cpu()\n",
    "lm_model.eval()\n",
    "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=20)\n",
    "\n",
    "for text_idx in range(start_tokens.shape[1]):\n",
    "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
    "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
    "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBwAQcOZKAjc",
    "outputId": "c635e8df-5416-4823-a85e-0ee9f6f9f30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> loved dvd tickets saw movies night thinking enjoyed early much years late <eos>\n",
      "<sos> <unk> favorite movie first dont find money realize movie gave boring one even started <eos>\n",
      "<sos> <unk> best movie still first nothing good stupid special special dont take dont think make sense know much appear exactly lot wonder good\n",
      "<sos> <unk> worst movie little movie everi much sucked like bad quite dont something boring worth get anything great else else boring boring bad\n"
     ]
    }
   ],
   "source": [
    "lm_model = lm_model.cpu()\n",
    "lm_model.eval()\n",
    "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=50)\n",
    "\n",
    "for text_idx in range(start_tokens.shape[1]):\n",
    "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
    "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
    "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5fpPXcct4zP"
   },
   "source": [
    "**Ответ:** как видно дадное кодирование приводит к повтору слов, что делает предложения менее связанными по смыслу, у величением k предложения получаются более связанными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T15:04:51.678260Z",
     "start_time": "2021-04-02T15:04:51.673587Z"
    },
    "id": "QQCZ-UPMt4zP"
   },
   "source": [
    "## Бонус. Cущественное улучшение качества. (до 3 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2H3f7-1t4zP"
   },
   "source": [
    "Та модель, которая использовалась в предыдущей части во многом заимствует улучшения LSTM из статьи [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/pdf/1708.02182.pdf). Вы можете попробовать применить другие варианты регуляризации из данной статьи для существенного улучшения качества LM.\n",
    "\n",
    "Например:\n",
    "1. Dropout для эмбеддингов\n",
    "2. Dropout входов и выходов RNN\n",
    "3. Регуляризация активаций (AR/TAR)\n",
    "4. NT-ASGD\n",
    "5. Tied веса эмбеддингов и софтмакса"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "313px",
    "left": "926px",
    "right": "27px",
    "top": "120px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
